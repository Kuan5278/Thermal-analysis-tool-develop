# thermal_analysis_platform_v10.3.5.py
# æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å° - v10.3.5 å‹•æ…‹é—œéµå­—æœç´¢ç°¡æ½”ç•Œé¢ç‰ˆ

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
import re
from datetime import datetime, date
import numpy as np
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import json
import os

# ç‰ˆæœ¬è³‡è¨Š
VERSION = "v10.3.5 Dynamic Keyword Search - Clean UI"
VERSION_DATE = "2025å¹´6æœˆ"

# =============================================================================
# 0. è¨ªå•è¨ˆæ•¸å™¨ (Visit Counter)
# =============================================================================

class VisitCounter:
    """è¨ªå•è¨ˆæ•¸å™¨"""
    
    def __init__(self, counter_file="visit_counter.json"):
        self.counter_file = counter_file
        self.data = self._load_counter()
    
    def _load_counter(self) -> dict:
        """è¼‰å…¥è¨ˆæ•¸å™¨æ•¸æ“š"""
        try:
            if os.path.exists(self.counter_file):
                with open(self.counter_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {
                    "total_visits": 0,
                    "daily_visits": {},
                    "first_visit": None,
                    "last_visit": None
                }
        except Exception:
            return {
                "total_visits": 0,
                "daily_visits": {},
                "first_visit": None,
                "last_visit": None
            }
    
    def _save_counter(self):
        """ä¿å­˜è¨ˆæ•¸å™¨æ•¸æ“š"""
        try:
            with open(self.counter_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    
    def increment_visit(self):
        """å¢åŠ è¨ªå•è¨ˆæ•¸"""
        now = datetime.now()
        today = now.strftime("%Y-%m-%d")
        
        # æ›´æ–°ç¸½è¨ªå•æ¬¡æ•¸
        self.data["total_visits"] += 1
        
        # æ›´æ–°ä»Šæ—¥è¨ªå•æ¬¡æ•¸
        if today not in self.data["daily_visits"]:
            self.data["daily_visits"][today] = 0
        self.data["daily_visits"][today] += 1
        
        # æ›´æ–°é¦–æ¬¡è¨ªå•æ™‚é–“
        if self.data["first_visit"] is None:
            self.data["first_visit"] = now.isoformat()
        
        # æ›´æ–°æœ€å¾Œè¨ªå•æ™‚é–“
        self.data["last_visit"] = now.isoformat()
        
        # æ¸…ç†èˆŠçš„æ—¥è¨ªå•è¨˜éŒ„ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
        self._cleanup_old_records()
        
        # ä¿å­˜æ•¸æ“š
        self._save_counter()
    
    def _cleanup_old_records(self):
        """æ¸…ç†30å¤©å‰çš„æ—¥è¨ªå•è¨˜éŒ„"""
        try:
            today = date.today()
            cutoff_date = today.replace(day=today.day-30) if today.day > 30 else today.replace(month=today.month-1, day=30)
            cutoff_str = cutoff_date.strftime("%Y-%m-%d")
            
            # ç§»é™¤30å¤©å‰çš„è¨˜éŒ„
            keys_to_remove = [k for k in self.data["daily_visits"].keys() if k < cutoff_str]
            for key in keys_to_remove:
                del self.data["daily_visits"][key]
        except Exception:
            pass
    
    def get_stats(self) -> dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        today = date.today().strftime("%Y-%m-%d")
        yesterday = (date.today().replace(day=date.today().day-1)).strftime("%Y-%m-%d") if date.today().day > 1 else None
        
        # è¨ˆç®—æœ€è¿‘7å¤©è¨ªå•é‡
        recent_7_days = 0
        for i in range(7):
            check_date = (date.today().replace(day=date.today().day-i)).strftime("%Y-%m-%d")
            recent_7_days += self.data["daily_visits"].get(check_date, 0)
        
        return {
            "total_visits": self.data["total_visits"],
            "today_visits": self.data["daily_visits"].get(today, 0),
            "yesterday_visits": self.data["daily_visits"].get(yesterday, 0) if yesterday else 0,
            "recent_7_days": recent_7_days,
            "first_visit": self.data["first_visit"],
            "last_visit": self.data["last_visit"],
            "active_days": len(self.data["daily_visits"])
        }

def display_visit_counter():
    """é¡¯ç¤ºè¨ªå•è¨ˆæ•¸å™¨"""
    # åˆå§‹åŒ–è¨ˆæ•¸å™¨
    if 'visit_counter' not in st.session_state:
        st.session_state.visit_counter = VisitCounter()
        st.session_state.visit_counted = False
    
    # åªåœ¨ç¬¬ä¸€æ¬¡åŠ è¼‰æ™‚è¨ˆæ•¸
    if not st.session_state.visit_counted:
        st.session_state.visit_counter.increment_visit()
        st.session_state.visit_counted = True
    
    # ç²å–çµ±è¨ˆæ•¸æ“š
    stats = st.session_state.visit_counter.get_stats()
    
    # é¡¯ç¤ºè¨ˆæ•¸å™¨
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
        
        # ä½¿ç”¨columnsä¾†ä¸¦æ’é¡¯ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                label="ğŸ’« ç¸½è¨ªå•",
                value=f"{stats['total_visits']:,}",
                help="è‡ªé¦–æ¬¡å•Ÿå‹•ä»¥ä¾†çš„ç¸½è¨ªå•æ¬¡æ•¸"
            )
            
            st.metric(
                label="ğŸ“… ä»Šæ—¥",
                value=f"{stats['today_visits']:,}",
                delta=f"+{stats['today_visits'] - stats['yesterday_visits']}" if stats['yesterday_visits'] > 0 else None,
                help="ä»Šæ—¥è¨ªå•æ¬¡æ•¸"
            )
        
        with col2:
            st.metric(
                label="ğŸ“ˆ è¿‘7å¤©",
                value=f"{stats['recent_7_days']:,}",
                help="æœ€è¿‘7å¤©ç¸½è¨ªå•æ¬¡æ•¸"
            )
            
            st.metric(
                label="ğŸ—“ï¸ æ´»èºå¤©æ•¸",
                value=f"{stats['active_days']:,}",
                help="æœ‰è¨ªå•è¨˜éŒ„çš„å¤©æ•¸"
            )
        
        # é¡¯ç¤ºè©³ç´°ä¿¡æ¯
        with st.expander("ğŸ“‹ è©³ç´°çµ±è¨ˆ", expanded=False):
            if stats['first_visit']:
                first_visit = datetime.fromisoformat(stats['first_visit'])
                st.write(f"ğŸš€ **é¦–æ¬¡ä½¿ç”¨ï¼š** {first_visit.strftime('%Y-%m-%d %H:%M')}")
            
            if stats['last_visit']:
                last_visit = datetime.fromisoformat(stats['last_visit'])
                st.write(f"â° **æœ€å¾Œä½¿ç”¨ï¼š** {last_visit.strftime('%Y-%m-%d %H:%M')}")
            
            st.write(f"ğŸ“Š **å¹³å‡æ¯æ—¥ï¼š** {stats['total_visits'] / max(stats['active_days'], 1):.1f} æ¬¡")
            
            # é¡¯ç¤ºæœ€è¿‘å¹¾å¤©çš„è¨ªå•è¶¨å‹¢
            recent_data = []
            for i in range(6, -1, -1):  # æœ€è¿‘7å¤©ï¼Œå€’åº
                check_date = date.today().replace(day=date.today().day-i) if date.today().day > i else date.today().replace(month=date.today().month-1, day=30-i+date.today().day)
                date_str = check_date.strftime("%Y-%m-%d")
                visits = st.session_state.visit_counter.data["daily_visits"].get(date_str, 0)
                recent_data.append({
                    'date': check_date.strftime("%m/%d"),
                    'visits': visits
                })
            
            if recent_data:
                st.write("ğŸ“ˆ **æœ€è¿‘7å¤©è¶¨å‹¢ï¼š**")
                trend_text = " | ".join([f"{d['date']}: {d['visits']}" for d in recent_data])
                st.code(trend_text, language=None)

# =============================================================================
# 1. æ•¸æ“šæ¨¡å‹å±¤ (Data Model Layer)
# =============================================================================

@dataclass
class LogMetadata:
    """Logæª”æ¡ˆå…ƒæ•¸æ“š"""
    filename: str
    log_type: str
    rows: int
    columns: int
    time_range: str
    file_size_kb: float

class LogData:
    """çµ±ä¸€çš„Logæ•¸æ“šæŠ½è±¡é¡"""
    def __init__(self, df: pd.DataFrame, metadata: LogMetadata):
        self.df = df
        self.metadata = metadata
        self._numeric_columns = None
    
    @property
    def numeric_columns(self) -> List[str]:
        """ç²å–æ•¸å€¼å‹æ¬„ä½"""
        if self._numeric_columns is None:
            self._numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()
        return self._numeric_columns
    
    def get_time_range(self) -> Tuple[float, float]:
        """ç²å–æ™‚é–“ç¯„åœï¼ˆç§’ï¼‰"""
        if self.df.empty:
            return (0.0, 0.0)
        return (0.0, self.df.index.total_seconds().max())
    
    def filter_by_time(self, x_limits: Tuple[float, float]):
        """æŒ‰æ™‚é–“ç¯„åœéæ¿¾æ•¸æ“š"""
        if x_limits is None:
            return self.df
        
        x_min_td = pd.to_timedelta(x_limits[0], unit='s')
        x_max_td = pd.to_timedelta(x_limits[1], unit='s')
        return self.df[(self.df.index >= x_min_td) & (self.df.index <= x_max_td)]

# =============================================================================
# 2. è§£æå™¨å±¤ (Parser Layer)
# =============================================================================

class LogParser(ABC):
    """è§£æå™¨æŠ½è±¡åŸºé¡"""
    
    @abstractmethod
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦èƒ½è§£ææ­¤æª”æ¡ˆ"""
        pass
    
    @abstractmethod
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è§£ææª”æ¡ˆ"""
        pass
    
    @property
    @abstractmethod
    def log_type(self) -> str:
        """Logé¡å‹åç¨±"""
        pass

class GPUMonParser(LogParser):
    """GPUMonè§£æå™¨"""
    
    @property
    def log_type(self) -> str:
        return "GPUMon Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºGPUMonæ ¼å¼"""
        try:
            file_content.seek(0)
            first_content = ""
            for _ in range(100):
                try:
                    line = file_content.readline().decode('utf-8', errors='ignore')
                    if not line:
                        break
                    first_content += line
                except:
                    break
            
            indicators = [
                'GPU Informations' in first_content,
                'Iteration, Date, Timestamp' in first_content,
                'Temperature GPU (C)' in first_content,
                'iteration' in first_content.lower() and 'gpu' in first_content.lower(),
                'NVVDD' in first_content,
                'FBVDD' in first_content
            ]
            
            return any(indicators)
        except:
            return False
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è§£æGPUMonæª”æ¡ˆ"""
        try:
            file_content.seek(0)
            content = file_content.read().decode('utf-8', errors='ignore')
            lines = content.split('\n')
            
            st.write(f"ğŸ” GPUMon Debug: æª”æ¡ˆç¸½è¡Œæ•¸ {len(lines)}")
            
            # å°‹æ‰¾æ¨™é¡Œè¡Œ
            header_row_index = self._find_header_row(lines)
            if header_row_index is None:
                return None
            
            # è§£ææ•¸æ“š
            df = self._parse_data_rows(lines, header_row_index)
            if df is None:
                return None
            
            # è™•ç†æ™‚é–“
            df = self._process_time_data(df)
            if df is None:
                return None
            
            # æ•¸å€¼è½‰æ›
            df = self._convert_numeric_columns(df)
            
            # æ·»åŠ å‰ç¶´ä¸¦è¨­ç½®ç´¢å¼•
            df = df.add_prefix('GPU: ')
            df.rename(columns={'GPU: time_index': 'time_index'}, inplace=True)
            result_df = df.set_index('time_index')
            
            # å‰µå»ºå…ƒæ•¸æ“š
            file_size_kb = len(content.encode('utf-8')) / 1024
            time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
            
            metadata = LogMetadata(
                filename=filename,
                log_type=self.log_type,
                rows=result_df.shape[0],
                columns=result_df.shape[1],
                time_range=time_range,
                file_size_kb=file_size_kb
            )
            
            st.write(f"ğŸ‰ GPUMonè§£ææˆåŠŸ! æœ€çµ‚æ•¸æ“š: {result_df.shape}")
            return LogData(result_df, metadata)
            
        except Exception as e:
            st.error(f"âŒ GPUMonè§£æéŒ¯èª¤: {e}")
            return None
    
    def _find_header_row(self, lines: List[str]) -> Optional[int]:
        """å°‹æ‰¾æ¨™é¡Œè¡Œ"""
        for i, line in enumerate(lines):
            line_lower = line.lower()
            if ('iteration' in line_lower and 'date' in line_lower and 'timestamp' in line_lower):
                st.write(f"âœ… æ‰¾åˆ°æ¨™é¡Œè¡Œåœ¨ç¬¬ {i+1} è¡Œ")
                return i
        
        # å‚™ç”¨æœå°‹
        for i, line in enumerate(lines):
            if line.count(',') > 10 and ('iteration' in line.lower() or 'gpu' in line.lower()):
                st.write(f"ğŸ“ å‚™ç”¨æ–¹å¼æ‰¾åˆ°å¯èƒ½çš„æ¨™é¡Œè¡Œåœ¨ç¬¬ {i+1} è¡Œ")
                return i
        
        return None
    
    def _parse_data_rows(self, lines: List[str], header_row_index: int) -> Optional[pd.DataFrame]:
        """è§£ææ•¸æ“šè¡Œ"""
        header_line = lines[header_row_index]
        st.write(f"ğŸ“‹ æ¨™é¡Œè¡Œå…§å®¹: {header_line[:100]}...")
        
        headers = [h.strip() for h in header_line.split(',')]
        st.write(f"ğŸ“Š è§£æåˆ° {len(headers)} å€‹æ¬„ä½")
        
        data_rows = []
        valid_data_count = 0
        
        for i in range(header_row_index + 1, min(header_row_index + 100, len(lines))):
            line = lines[i].strip()
            if line and not line.startswith(','):
                try:
                    row_data = [cell.strip() for cell in line.split(',')]
                    if len(row_data) >= 3:
                        if (row_data[0].isdigit() or 
                            any(cell and cell != 'N/A' for cell in row_data[:5])):
                            data_rows.append(row_data)
                            valid_data_count += 1
                            if valid_data_count <= 3:
                                st.write(f"âœ… æœ‰æ•ˆæ•¸æ“šè¡Œ {valid_data_count}: {row_data[:5]}...")
                except Exception:
                    continue
        
        st.write(f"ğŸ“ˆ æ‰¾åˆ° {len(data_rows)} è¡Œæœ‰æ•ˆæ•¸æ“š")
        
        if not data_rows:
            return None
        
        # å‰µå»ºDataFrame
        max_cols = max(len(headers), max(len(row) for row in data_rows))
        
        while len(headers) < max_cols:
            headers.append(f'Column_{len(headers)}')
        
        for row in data_rows:
            while len(row) < max_cols:
                row.append('')
        
        df = pd.DataFrame(data_rows, columns=headers[:max_cols])
        st.write(f"ğŸ¯ DataFrameå‰µå»ºæˆåŠŸ: {df.shape}")
        
        return df
    
    def _process_time_data(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """è™•ç†æ™‚é–“æ•¸æ“š"""
        try:
            if 'Date' in df.columns and 'Timestamp' in df.columns:
                st.write("ğŸ• è™•ç†æ™‚é–“æ ¼å¼: Date + Timestamp")
                
                df['Timestamp_fixed'] = df['Timestamp'].str.replace(r':(\d{3})$', r'.\1', regex=True)
                st.write(f"ğŸ”§ æ™‚é–“æ ¼å¼ä¿®æ­£: {df['Timestamp'].iloc[0]} -> {df['Timestamp_fixed'].iloc[0]}")
                
                df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Timestamp_fixed'], errors='coerce')
                st.write(f"ğŸ“… åˆä½µå¾Œæ™‚é–“: {df['DateTime'].iloc[0]}")
                
            else:
                df['DateTime'] = pd.to_datetime('2025-01-01') + pd.to_timedelta(range(len(df)), unit='s')
            
            valid_datetime_count = df['DateTime'].notna().sum()
            st.write(f"ğŸ“Š æˆåŠŸè§£æçš„æ™‚é–“é»: {valid_datetime_count}/{len(df)}")
            
            if valid_datetime_count > 0:
                df['time_index'] = df['DateTime'] - df['DateTime'].iloc[0]
                valid_mask = df['time_index'].notna()
                df = df[valid_mask].copy()
                st.write(f"â° æ™‚é–“è§£ææˆåŠŸï¼Œæœ€çµ‚æœ‰æ•ˆæ•¸æ“š: {len(df)} è¡Œ")
            else:
                df['time_index'] = pd.to_timedelta(range(len(df)), unit='s')
            
            return df
            
        except Exception as e:
            st.write(f"âš ï¸ æ™‚é–“è§£æç•°å¸¸: {e}")
            df['time_index'] = pd.to_timedelta(range(len(df)), unit='s')
            return df
    
    def _convert_numeric_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """è½‰æ›æ•¸å€¼å‹æ¬„ä½"""
        numeric_count = 0
        for col in df.columns:
            if col not in ['Date', 'Timestamp', 'DateTime', 'time_index', 'Iteration']:
                try:
                    df[col] = df[col].replace(['N/A', 'n/a', '', ' '], np.nan)
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    if not df[col].isna().all():
                        numeric_count += 1
                except:
                    pass
        
        st.write(f"ğŸ”¢ è½‰æ›äº† {numeric_count} å€‹æ•¸å€¼æ¬„ä½")
        return df

class PTATParser(LogParser):
    """PTATè§£æå™¨"""
    
    @property
    def log_type(self) -> str:
        return "PTAT Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        try:
            file_content.seek(0)
            first_content = file_content.read(2000).decode('utf-8', errors='ignore')
            return ('MSR Package Temperature' in first_content or 
                    'Version,Date,Time' in first_content)
        except:
            return False
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        try:
            file_content.seek(0)
            df = pd.read_csv(file_content, header=0, thousands=',', low_memory=False)
            df.columns = df.columns.str.strip()
            
            if 'Time' not in df.columns:
                return None
            
            time_series = df['Time'].astype(str).str.strip()
            time_series_cleaned = time_series.str.replace(r':(\d{3})$', r'.\1', regex=True)
            datetime_series = pd.to_datetime(time_series_cleaned, format='%H:%M:%S.%f', errors='coerce')
            
            valid_times_mask = datetime_series.notna()
            df = df[valid_times_mask].copy()
            
            if df.empty:
                return None
            
            valid_datetimes = datetime_series[valid_times_mask]
            df['time_index'] = valid_datetimes - valid_datetimes.iloc[0]
            df = df.add_prefix('PTAT: ')
            df.rename(columns={'PTAT: time_index': 'time_index'}, inplace=True)
            
            result_df = df.set_index('time_index')
            
            # å‰µå»ºå…ƒæ•¸æ“š
            file_size_kb = len(file_content.getvalue()) / 1024
            time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
            
            metadata = LogMetadata(
                filename=filename,
                log_type=self.log_type,
                rows=result_df.shape[0],
                columns=result_df.shape[1],
                time_range=time_range,
                file_size_kb=file_size_kb
            )
            
            return LogData(result_df, metadata)
            
        except Exception as e:
            return None

class YokogawaParser(LogParser):
    """ğŸ†• YOKOGAWAè§£æå™¨ - å‹•æ…‹é—œéµå­—æœç´¢ç‰ˆæœ¬"""
    
    @property
    def log_type(self) -> str:
        return "YOKOGAWA Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        # YOKOGAWAä½œç‚ºå…œåº•è§£æå™¨ï¼Œç¸½æ˜¯è¿”å›True
        return True
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        st.write(f"ğŸš€ YOKOGAWAè§£æå™¨å•Ÿå‹• (v10.3.5ç°¡æ½”ç•Œé¢ç‰ˆ) - æª”æ¡ˆ: {filename}")
        
        try:
            is_excel = '.xlsx' in filename.lower() or '.xls' in filename.lower()
            read_func = pd.read_excel if is_excel else pd.read_csv
            
            st.write(f"ğŸ” æª”æ¡ˆé¡å‹: {'Excel' if is_excel else 'CSV'}")
            
            # ğŸ†• å‹•æ…‹æœç´¢å¯èƒ½çš„ header è¡Œ
            possible_headers = self._find_possible_headers(file_content, is_excel, read_func)
            
            df = None
            found_time_col = None
            successful_header = None
            
            st.write(f"ğŸ“‹ å‹•æ…‹æœç´¢æ‰¾åˆ°å€™é¸headerè¡Œ: {possible_headers}")
            
            for header_row in possible_headers:
                try:
                    file_content.seek(0)
                    df = read_func(file_content, header=header_row, thousands=',')
                    df.columns = df.columns.str.strip()
                    
                    st.write(f"  ğŸ” å˜—è©¦header_row={header_row}, å¾—åˆ°å½¢ç‹€: {df.shape}")
                    st.write(f"  ğŸ“Š æ¬„ä½æ¨£æœ¬: {list(df.columns)[:8]}...")
                    
                    time_candidates = ['Time', 'TIME', 'time', 'Date', 'DATE', 'date', 
                                     'DateTime', 'DATETIME', 'datetime', 'æ™‚é–“', 'æ—¥æœŸæ™‚é–“',
                                     'Timestamp', 'TIMESTAMP', 'timestamp']
                    
                    for candidate in time_candidates:
                        if candidate in df.columns:
                            found_time_col = candidate
                            successful_header = header_row
                            st.write(f"  âœ… æ‰¾åˆ°æ™‚é–“æ¬„ä½: {candidate}")
                            break
                    
                    if found_time_col:
                        break
                        
                except Exception as e:
                    st.write(f"  âŒ header_row={header_row} å¤±æ•—: {e}")
                    continue
            
            if df is None or found_time_col is None:
                error_msg = f"âŒ ç„¡æ³•æ‰¾åˆ°æ™‚é–“æ¬„ä½ã€‚å»ºè­°ä¸Šå‚³å®Œæ•´çš„YOKOGAWAæª”æ¡ˆä»¥ç²å¾—æœ€ä½³æ•ˆæœã€‚"
                st.error(error_msg)
                st.info("ğŸ’¡ æç¤ºï¼šå‹•æ…‹æœç´¢æ”¯æ´éƒ¨åˆ†æª”æ¡ˆï¼Œä½†å®Œæ•´æª”æ¡ˆè§£ææ•ˆæœæ›´ä½³")
                return None
            
            time_column = found_time_col
            st.write(f"âœ… æˆåŠŸè§£æï¼Œä½¿ç”¨header_row={successful_header}, æ™‚é–“æ¬„ä½='{time_column}'")
            st.write(f"ğŸ“Š DataFrameæœ€çµ‚å½¢ç‹€: {df.shape}")
            
            # ğŸ†• å‹•æ…‹é‡å‘½åé‚è¼¯ - æœç´¢ CH å’Œ Tag è¡Œ
            if is_excel:
                st.write("=" * 50)
                st.write("ğŸ·ï¸ é–‹å§‹YOKOGAWAæ¬„ä½é‡å‘½åé‚è¼¯ (v10.3.5ç°¡æ½”ç•Œé¢ç‰ˆ)")
                st.write("=" * 50)
                
                try:
                    # ğŸ†• å‹•æ…‹å°‹æ‰¾ CH è¡Œå’Œ Tag è¡Œ
                    ch_row_idx, tag_row_idx = self._find_ch_tag_rows(file_content, successful_header)
                    
                    if ch_row_idx is not None and tag_row_idx is not None:
                        st.write(f"ğŸ¯ å‹•æ…‹æœç´¢æˆåŠŸï¼CHè¡Œåœ¨ç¬¬{ch_row_idx+1}è¡Œï¼ŒTagè¡Œåœ¨ç¬¬{tag_row_idx+1}è¡Œ")
                        
                        # è®€å–CHè¡Œ
                        file_content.seek(0)
                        ch_row = pd.read_excel(file_content, header=None, skiprows=ch_row_idx, nrows=1).iloc[0]
                        st.write(f"âœ… CHè¡Œè®€å–æˆåŠŸï¼Œé•·åº¦: {len(ch_row)}")
                        
                        # è®€å–Tagè¡Œ
                        file_content.seek(0)
                        tag_row = pd.read_excel(file_content, header=None, skiprows=tag_row_idx, nrows=1).iloc[0]
                        st.write(f"âœ… Tagè¡Œè®€å–æˆåŠŸï¼Œé•·åº¦: {len(tag_row)}")
                        
                        # åŸ·è¡Œé‡å‘½å
                        df = self._perform_renaming(df, ch_row, tag_row)
                    else:
                        st.write("âš ï¸ æœªæ‰¾åˆ°CH/Tagè¡Œï¼Œä½¿ç”¨åŸå§‹æ¬„ä½åç¨±")
                        st.info("ğŸ’¡ é€™å¯èƒ½æ˜¯éƒ¨åˆ†æ“·å–çš„æª”æ¡ˆï¼Œä»å¯é€²è¡ŒåŸºæœ¬åˆ†æ")
                        
                except Exception as e:
                    st.write(f"âŒ å‹•æ…‹é‡å‘½åéç¨‹ç•°å¸¸: {e}")
                    st.write("âš ï¸ å°‡ç¹¼çºŒä½¿ç”¨åŸå§‹æ¬„ä½åç¨±")
            
            # ç¹¼çºŒè™•ç†æ™‚é–“å’Œå…¶ä»–é‚è¼¯...
            result = self._process_time_and_finalize(df, time_column, file_content, filename)
            
            return result
            
        except Exception as e:
            st.write(f"âŒ YOKOGAWAè§£æå™¨æ•´é«”ç•°å¸¸: {e}")
            import traceback
            st.write("å®Œæ•´éŒ¯èª¤å †ç–Š:")
            st.code(traceback.format_exc())
            return None
    
    def _find_possible_headers(self, file_content: io.BytesIO, is_excel: bool, read_func) -> List[int]:
        """ğŸ†• å‹•æ…‹æœç´¢å¯èƒ½çš„headerè¡Œ - ç°¡æ½”ç‰ˆ"""
        if not is_excel:
            return [0, 1, 2]  # CSV é€šå¸¸åœ¨å‰å¹¾è¡Œ
        
        # Excel æª”æ¡ˆï¼šå‹•æ…‹æœç´¢åŒ…å«æ™‚é–“ç›¸é—œæ¬„ä½çš„è¡Œ
        possible_headers = []
        
        st.write("ğŸ” é–‹å§‹æœç´¢åŒ…å«æ™‚é–“é—œéµè©çš„headerè¡Œ...")
        
        # åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°æœç´¢éç¨‹
        with st.expander("ğŸ“Š Headerè¡Œæœç´¢è©³ç´°éç¨‹", expanded=False):
            st.write("**ç¬¬ä¸€éšæ®µï¼šé—œéµå­—æœç´¢**")
            
            # ç¬¬ä¸€éšæ®µï¼šé—œéµå­—æœç´¢
            time_keywords = ['time', 'date', 'timestamp', 'æ™‚é–“', 'æ—¥æœŸ']
            
            for pos in range(0, 50):  # æœç´¢å‰50è¡Œ
                try:
                    file_content.seek(0)
                    test_df = read_func(file_content, header=pos, nrows=1)
                    columns_str = ' '.join(str(col).lower() for col in test_df.columns if pd.notna(col))
                    
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“ç›¸é—œé—œéµè©
                    if any(keyword in columns_str for keyword in time_keywords):
                        possible_headers.append(pos)
                        found_keywords = [kw for kw in time_keywords if kw in columns_str]
                        st.write(f"  ğŸ¯ ç¬¬{pos+1}è¡ŒåŒ…å«æ™‚é–“é—œéµè©: {found_keywords}")
                        
                except Exception:
                    continue
            
            # ç¬¬äºŒéšæ®µï¼šå¦‚æœé—œéµå­—æœç´¢å¤±æ•—ï¼Œä½¿ç”¨çµæ§‹æœç´¢
            if not possible_headers:
                st.write("**ç¬¬äºŒéšæ®µï¼šçµæ§‹æœç´¢**")
                for pos in range(0, 50):
                    try:
                        file_content.seek(0)
                        test_df = read_func(file_content, header=pos, nrows=1)
                        if test_df.shape[1] >= 5:  # è‡³å°‘è¦æœ‰5å€‹æ¬„ä½
                            possible_headers.append(pos)
                            st.write(f"  ğŸ“Š ç¬¬{pos+1}è¡Œæœ‰{test_df.shape[1]}å€‹æ¬„ä½")
                            if len(possible_headers) >= 10:  # æœ€å¤šæ‰¾10å€‹å€™é¸
                                break
                    except Exception:
                        continue
            
            # ç¬¬ä¸‰éšæ®µï¼šå¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨é è¨­å€¼
            if not possible_headers:
                possible_headers = [29, 28, 30, 27, 26, 31, 32] if is_excel else [0, 1, 2]
                st.write("**ç¬¬ä¸‰éšæ®µï¼šä½¿ç”¨é è¨­æœç´¢ç¯„åœ**")
                st.write(f"  ä½¿ç”¨é è¨­ä½ç½®: {possible_headers}")
        
        # é¡¯ç¤ºç°¡æ½”çš„æœç´¢çµæœ
        if possible_headers:
            st.write(f"âœ… æ‰¾åˆ° {len(possible_headers)} å€‹å€™é¸headerè¡Œ: {possible_headers[:5]}{'...' if len(possible_headers) > 5 else ''}")
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ°æ˜ç¢ºçš„headerè¡Œï¼Œå°‡ä½¿ç”¨é è¨­ç¯„åœ")
        
        return possible_headers
    
    def _find_ch_tag_rows(self, file_content: io.BytesIO, header_row: int) -> Tuple[Optional[int], Optional[int]]:
        """ğŸ†• å‹•æ…‹å°‹æ‰¾CHè¡Œå’ŒTagè¡Œ - ç°¡æ½”ç•Œé¢ç‰ˆ"""
        ch_row_idx = None
        tag_row_idx = None
        
        st.write(f"ğŸ” åœ¨headerè¡Œ({header_row+1})é™„è¿‘æœç´¢CHå’ŒTagè¡Œ...")
        
        # æ“´å¤§æœç´¢ç¯„åœ
        search_range = range(max(0, header_row - 8), header_row + 1)
        
        # å‰µå»ºè©³ç´°æ—¥èªŒçš„æ‘ºç–Šå€åŸŸ
        with st.expander("ğŸ“‹ è©³ç´°æ–‡ä»¶çµæ§‹åˆ†æ", expanded=False):
            st.write("**é€è¡Œå…§å®¹åˆ†æï¼š**")
            
            # åˆ†ææ‰€æœ‰å€™é¸è¡Œçš„å…§å®¹
            row_analysis = []
            for idx in search_range:
                try:
                    file_content.seek(0)
                    test_row = pd.read_excel(file_content, header=None, skiprows=idx, nrows=1).iloc[0]
                    
                    # åˆ†æé€™ä¸€è¡Œçš„å…§å®¹
                    ch_count = 0
                    meaningful_tags = []
                    numeric_count = 0
                    empty_count = 0
                    all_values = []
                    
                    for val in test_row:
                        if pd.isna(val) or str(val).strip() == '':
                            empty_count += 1
                        else:
                            val_str = str(val).strip()
                            all_values.append(val_str)
                            
                            if val_str.upper().startswith('CH'):
                                ch_count += 1
                            elif self._is_meaningful_tag(val):
                                meaningful_tags.append(val_str)
                            else:
                                try:
                                    float(val_str)
                                    numeric_count += 1
                                except ValueError:
                                    pass
                    
                    analysis = {
                        'row_idx': idx,
                        'ch_count': ch_count,
                        'meaningful_tags': meaningful_tags,
                        'meaningful_count': len(meaningful_tags),
                        'numeric_count': numeric_count,
                        'empty_count': empty_count,
                        'all_values': all_values[:10],
                        'total_cells': len(test_row)
                    }
                    row_analysis.append(analysis)
                    
                    # åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°åˆ†æ
                    st.write(f"  ç¬¬{idx+1}è¡Œ: CH={ch_count}, ç”¨æˆ¶æ¨™ç±¤={len(meaningful_tags)}, æ•¸å­—={numeric_count}, ç©ºå€¼={empty_count}")
                    if meaningful_tags:
                        st.write(f"    ğŸ·ï¸ ç”¨æˆ¶æ¨™ç±¤: {meaningful_tags[:5]}")
                    if all_values:
                        st.write(f"    ğŸ“ å…§å®¹æ¨£æœ¬: {all_values[:8]}")
                        
                except Exception as e:
                    st.write(f"  ç¬¬{idx+1}è¡Œ: åˆ†æå¤±æ•— - {e}")
                    continue
        
        # å°‹æ‰¾CHè¡Œï¼ˆç°¡æ½”é¡¯ç¤ºï¼‰
        for analysis in row_analysis:
            if analysis['ch_count'] >= 3:
                ch_row_idx = analysis['row_idx']
                st.write(f"âœ… æ‰¾åˆ°CHè¡Œåœ¨ç¬¬{ch_row_idx+1}è¡Œ (å«{analysis['ch_count']}å€‹CHæ¬„ä½)")
                break
        
        # å°‹æ‰¾Tagè¡Œï¼ˆç°¡æ½”é¡¯ç¤ºä¸»è¦çµæœï¼‰
        if ch_row_idx is not None:
            # æª¢æŸ¥CHè¡Œé™„è¿‘çš„è¡Œ
            tag_candidates = []
            for analysis in row_analysis:
                if (analysis['row_idx'] != ch_row_idx and 
                    analysis['row_idx'] < header_row):
                    tag_candidates.append(analysis)
            
            # åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°æœç´¢éç¨‹
            with st.expander("ğŸ” Tagè¡Œæœç´¢è©³ç´°éç¨‹", expanded=False):
                st.write(f"**Tagè¡Œå€™é¸: {[a['row_idx']+1 for a in tag_candidates]}**")
                
                best_tag_row = None
                max_tags = 0
                
                for candidate in tag_candidates:
                    st.write(f"  æª¢æŸ¥ç¬¬{candidate['row_idx']+1}è¡Œ:")
                    st.write(f"    ç”¨æˆ¶æ¨™ç±¤æ•¸é‡: {candidate['meaningful_count']}")
                    st.write(f"    æ¨™ç±¤å…§å®¹: {candidate['meaningful_tags'][:5]}")
                    
                    if candidate['meaningful_count'] > 0:
                        if candidate['meaningful_count'] > max_tags:
                            max_tags = candidate['meaningful_count']
                            best_tag_row = candidate
                            st.write(f"    âœ… ç›®å‰æœ€ä½³Tagè¡Œï¼ˆæ¨™ç±¤æ•¸: {max_tags}ï¼‰")
                        else:
                            st.write(f"    âœ“ å¯ç”¨Tagè¡Œï¼ˆæ¨™ç±¤æ•¸: {candidate['meaningful_count']}ï¼‰")
                    else:
                        st.write(f"    âŒ ç„¡ç”¨æˆ¶æ¨™ç±¤")
                
                if best_tag_row:
                    tag_row_idx = best_tag_row['row_idx']
                    st.write(f"  ğŸ¯ **é¸å®šTagè¡Œ**: ç¬¬{tag_row_idx+1}è¡Œï¼ˆå«{max_tags}å€‹ç”¨æˆ¶æ¨™ç±¤ï¼‰")
            
            # é¡¯ç¤ºç°¡æ½”çš„ä¸»è¦çµæœ
            if tag_row_idx is not None:
                # ç²å–æœ€ä½³Tagè¡Œçš„ä¿¡æ¯
                for analysis in row_analysis:
                    if analysis['row_idx'] == tag_row_idx:
                        st.write(f"âœ… æ‰¾åˆ°Tagè¡Œåœ¨ç¬¬{tag_row_idx+1}è¡Œ (å«{analysis['meaningful_count']}å€‹ç”¨æˆ¶æ¨™ç±¤)")
                        if analysis['meaningful_tags']:
                            st.write(f"   ğŸ·ï¸ ç”¨æˆ¶æ¨™ç±¤æ¨£æœ¬: {analysis['meaningful_tags'][:5]}")
                        break
        
        # æœ€çµ‚çµæœé è¦½
        if ch_row_idx is not None and tag_row_idx is not None:
            st.success(f"ğŸ¯ æœç´¢æˆåŠŸï¼CHè¡Œ: ç¬¬{ch_row_idx+1}è¡Œï¼ŒTagè¡Œ: ç¬¬{tag_row_idx+1}è¡Œ")
            
            # åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°å…§å®¹é è¦½
            with st.expander("ğŸ“‹ CH/Tagè¡Œå…§å®¹é è¦½", expanded=False):
                try:
                    file_content.seek(0)
                    ch_row_content = pd.read_excel(file_content, header=None, skiprows=ch_row_idx, nrows=1).iloc[0]
                    file_content.seek(0)
                    tag_row_content = pd.read_excel(file_content, header=None, skiprows=tag_row_idx, nrows=1).iloc[0]
                    
                    # CHè¡Œé è¦½
                    ch_values = [str(val) for val in ch_row_content if pd.notna(val)][:8]
                    st.write(f"**CHè¡Œå…§å®¹æ¨£æœ¬:**")
                    st.code(f"{ch_values}")
                    
                    # Tagè¡Œé è¦½ï¼Œé‡é»é¡¯ç¤ºç”¨æˆ¶æ¨™ç±¤
                    tag_values = []
                    user_tags = []
                    for val in tag_row_content:
                        if pd.notna(val):
                            val_str = str(val).strip()
                            tag_values.append(val_str)
                            if self._is_meaningful_tag(val):
                                user_tags.append(val_str)
                    
                    st.write(f"**Tagè¡Œå…§å®¹æ¨£æœ¬:**")
                    st.code(f"{tag_values[:8]}")
                    st.write(f"**è­˜åˆ¥çš„ç”¨æˆ¶æ¨™ç±¤:**")
                    st.code(f"{user_tags}")
                    
                except Exception as e:
                    st.error(f"å…§å®¹é è¦½å¤±æ•—: {e}")
                    
        elif ch_row_idx is not None:
            st.warning(f"âš ï¸ åªæ‰¾åˆ°CHè¡Œ: ç¬¬{ch_row_idx+1}è¡Œï¼Œå°‡åªä½¿ç”¨CHè¡Œå‘½å")
        else:
            st.error("âŒ æœªæ‰¾åˆ°CH/Tagè¡Œ")
        
        return ch_row_idx, tag_row_idx
    
    def _is_meaningful_tag(self, tag_val) -> bool:
        """åˆ¤æ–·Tagå€¼æ˜¯å¦æœ‰æ„ç¾©ï¼ˆç”¨æˆ¶è‡ªå®šç¾©ä»£è™Ÿï¼‰- ä¿®æ­£ç‰ˆ"""
        if pd.isna(tag_val):
            return False
            
        tag_str = str(tag_val).strip()
        
        # æ’é™¤ç©ºå€¼
        if tag_str in ['', 'nan', 'NaN', 'None']:
            return False
            
        # ğŸ”§ ä¿®æ­£ï¼šä¸è¦æ’é™¤æ‰€æœ‰çš„ "Tag" è©ï¼Œåªæ’é™¤å–®ç¨çš„ "Tag"
        if tag_str.upper() == 'TAG':
            return False
            
        # æ’é™¤å…¶ä»–æ˜é¡¯çš„æ¨™é¡Œè©ï¼Œä½†ä¿ç•™å¯èƒ½çš„ç”¨æˆ¶æ¨™ç±¤
        system_titles = ['CHANNEL', 'CH', 'POINT', 'TEMP', 'SENSOR']
        if tag_str.upper() in system_titles:
            return False
            
        # ğŸ”§ é‡è¦ä¿®æ­£ï¼šä¸è¦æ’é™¤çœ‹èµ·ä¾†åƒæ•¸æ“šçš„çŸ­å­—ç¬¦ä¸²
        # åƒ U5, U19, L8 é€™æ¨£çš„ç”¨æˆ¶æ¨™ç±¤å¾ˆå¯èƒ½è¢«èª¤åˆ¤ç‚ºç„¡æ„ç¾©
        
        # å¦‚æœæ˜¯å–®å€‹å­—æ¯+æ•¸å­—çš„çµ„åˆï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ¶æ¨™ç±¤ï¼ˆå¦‚ U5, U19, L8ï¼‰
        if len(tag_str) <= 4 and any(c.isalpha() for c in tag_str) and any(c.isdigit() for c in tag_str):
            return True
            
        # å¦‚æœåŒ…å«ä¸‹åŠƒç·šï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ¶æ¨™ç±¤ï¼ˆå¦‚ CPU_Tcï¼‰
        if '_' in tag_str:
            return True
            
        # æ’é™¤çœ‹èµ·ä¾†ç´”æ•¸å­—ä¸”åƒæ¸¬é‡æ•¸æ“šçš„å€¼ï¼ˆä½†ä¿ç•™çŸ­æ•¸å­—ï¼Œå¯èƒ½æ˜¯ç·¨è™Ÿï¼‰
        try:
            float_val = float(tag_str)
            # å¦‚æœæ˜¯çœ‹èµ·ä¾†åƒæ¸¬é‡æ•¸æ“šçš„æ•¸å­—ï¼ˆæº«åº¦ç¯„åœã€å¸¶å°æ•¸é»çš„é•·æ•¸å­—ï¼‰ï¼Œæ’é™¤
            if (0 <= float_val <= 200 and '.' in tag_str and len(tag_str) > 4):
                return False
            # çŸ­æ•¸å­—å¯èƒ½æ˜¯ç·¨è™Ÿï¼Œä¿ç•™
            elif len(tag_str) <= 3:
                return True
        except ValueError:
            pass  # ä¸æ˜¯æ•¸å­—ï¼Œç¹¼çºŒæª¢æŸ¥
            
        # ğŸ”§ å°æ–¼å…¶ä»–æƒ…æ³ï¼Œåªè¦é•·åº¦å¤§æ–¼1å°±èªç‚ºæ˜¯æœ‰æ„ç¾©çš„ï¼ˆé™ä½é–€æª»ï¼‰
        if len(tag_str) >= 2:
            return True
            
        return False
    
    def _is_valid_ch(self, ch_val) -> bool:
        """åˆ¤æ–·CHå€¼æ˜¯å¦æœ‰æ•ˆ"""
        if pd.isna(ch_val):
            return False
            
        ch_str = str(ch_val).strip()
        
        # æ’é™¤ç©ºå€¼
        if ch_str in ['', 'nan', 'NaN', 'None']:
            return False
            
        # å¿…é ˆæ˜¯CHé–‹é ­æˆ–åŒ…å«CHçš„æ ¼å¼
        if ch_str.upper().startswith('CH') or 'CH' in ch_str.upper():
            return True
            
        return False
    
    def _perform_renaming(self, df: pd.DataFrame, ch_row: pd.Series, tag_row: pd.Series) -> pd.DataFrame:
        """åŸ·è¡Œé‡å‘½åé‚è¼¯ - ç°¡æ½”ç•Œé¢ç‰ˆ"""
        st.write("ğŸ”„ é–‹å§‹æ™ºèƒ½é‡å‘½åè™•ç† (Tagå„ªå…ˆ, CHå‚™é¸)...")
        
        # å®šç¾©éœ€è¦ä¿è­·çš„é—œéµæ¬„ä½
        protected_columns = {
            'Date', 'TIME', 'Time', 'time', 'DATE', 'date',
            'DateTime', 'DATETIME', 'datetime', 
            'Timestamp', 'TIMESTAMP', 'timestamp',
            'sec', 'SEC', 'RT', 'rt', 'æ™‚é–“', 'æ—¥æœŸæ™‚é–“'
        }
        
        new_column_names = {}
        rename_log = []
        
        # çµ±è¨ˆä¿¡æ¯
        tag_used = 0
        ch_used = 0
        protected_count = 0
        original_kept = 0
        
        for i, original_col in enumerate(df.columns):
            # ä¿è­·é—œéµæ¬„ä½
            if original_col in protected_columns:
                final_name = original_col
                rename_log.append(f"æ¬„ä½{i+1}: '{original_col}' â†’ ğŸ›¡ï¸ä¿è­·æ¬„ä½")
                protected_count += 1
                new_column_names[original_col] = final_name
                continue
            
            # ç²å–Tagå€¼ï¼ˆç”¨æˆ¶è‡ªå®šç¾©ä»£è™Ÿï¼‰
            tag_name = ""
            if i < len(tag_row):
                tag_val = tag_row.iloc[i]
                if self._is_meaningful_tag(tag_val):
                    tag_name = str(tag_val).strip()
            
            # ç²å–CHå€¼ï¼ˆCHç·¨è™Ÿï¼‰
            ch_name = ""
            if i < len(ch_row):
                ch_val = ch_row.iloc[i]
                if self._is_valid_ch(ch_val):
                    ch_name = str(ch_val).strip()
            
            # æ±ºå®šæœ€çµ‚åç¨±ï¼šTagå„ªå…ˆï¼ŒCHå‚™é¸ï¼ŒåŸåä¿æŒ
            if tag_name:
                final_name = tag_name
                rename_log.append(f"æ¬„ä½{i+1}: '{original_col}' â†’ ğŸ·ï¸Tag'{tag_name}'")
                tag_used += 1
            elif ch_name:
                final_name = ch_name
                rename_log.append(f"æ¬„ä½{i+1}: '{original_col}' â†’ ğŸ“‹CH'{ch_name}'")
                ch_used += 1
            else:
                final_name = original_col
                rename_log.append(f"æ¬„ä½{i+1}: '{original_col}' â†’ ğŸ“ä¿æŒåŸå")
                original_kept += 1
            
            new_column_names[original_col] = final_name
        
        # åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°é‡å‘½åè¨ˆåŠƒ
        with st.expander("ğŸ“ è©³ç´°é‡å‘½åè¨ˆåŠƒ", expanded=False):
            st.write("**é‡å‘½åæ±ºç­–éç¨‹ï¼š**")
            for log_entry in rename_log[:15]:  # é¡¯ç¤ºå‰15å€‹
                st.write(f"  {log_entry}")
            
            if len(rename_log) > 15:
                st.write(f"  ... é‚„æœ‰ {len(rename_log) - 15} å€‹æ¬„ä½")
            
            # é¡¯ç¤ºé‡å‘½åæ¨£æœ¬
            actual_changes = [(old, new) for old, new in new_column_names.items() if old != new and old not in protected_columns]
            if len(actual_changes) > 0:
                st.write("**é‡å‘½åæ¨£æœ¬ï¼š**")
                for old, new in actual_changes[:8]:
                    st.write(f"  '{old}' â†’ '{new}'")
        
        # åŸ·è¡Œé‡å‘½å
        df.rename(columns=new_column_names, inplace=True)
        
        # é¡¯ç¤ºç°¡æ½”çš„çµ±è¨ˆçµæœ
        st.success("âœ… æ™ºèƒ½é‡å‘½åå®Œæˆï¼")
        
        # ä½¿ç”¨ columns ä¾†ä¸¦æ’é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ·ï¸ Tagå‘½å", f"{tag_used} å€‹")
        with col2:
            st.metric("ğŸ“‹ CHå‘½å", f"{ch_used} å€‹")
        with col3:
            st.metric("ğŸ›¡ï¸ ä¿è­·æ¬„ä½", f"{protected_count} å€‹")
        with col4:
            st.metric("ğŸ“ ä¿æŒåŸå", f"{original_kept} å€‹")
        
        return df
    
    def _process_time_and_finalize(self, df: pd.DataFrame, time_column: str, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è™•ç†æ™‚é–“ä¸¦å®Œæˆè§£æ"""
        st.write("â° é–‹å§‹è™•ç†æ™‚é–“æ•¸æ“š...")
        time_series = df[time_column].astype(str).str.strip()
        
        try:
            df['time_index'] = pd.to_timedelta(time_series + ':00').fillna(pd.to_timedelta('00:00:00'))
            if df['time_index'].isna().all():
                raise ValueError("Timedelta è½‰æ›å¤±æ•—")
            st.write("âœ… æ™‚é–“è§£ææˆåŠŸ (Timedeltaæ ¼å¼)")
        except:
            try:
                datetime_series = pd.to_datetime(time_series, format='%H:%M:%S', errors='coerce')
                if datetime_series.notna().sum() == 0:
                    datetime_series = pd.to_datetime(time_series, errors='coerce')
                df['time_index'] = datetime_series - datetime_series.iloc[0]
                st.write("âœ… æ™‚é–“è§£ææˆåŠŸ (DateTimeæ ¼å¼)")
            except Exception as e:
                st.write(f"âŒ æ™‚é–“è§£æå¤±æ•—: {e}")
                return None
        
        valid_times_mask = df['time_index'].notna()
        if valid_times_mask.sum() == 0:
            st.write("âŒ æ²’æœ‰æœ‰æ•ˆçš„æ™‚é–“æ•¸æ“š")
            return None
        
        df = df[valid_times_mask].copy()
        
        if len(df) > 0:
            start_time = df['time_index'].iloc[0]
            df['time_index'] = df['time_index'] - start_time
        
        # æ•¸å€¼è½‰æ›
        numeric_columns = df.select_dtypes(include=['number']).columns
        numeric_converted = 0
        for col in numeric_columns:
            if col != 'time_index':
                try:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    numeric_converted += 1
                except:
                    pass
        
        st.write(f"ğŸ”¢ æ•¸å€¼è½‰æ›å®Œæˆï¼Œè™•ç†äº† {numeric_converted} å€‹æ¬„ä½")
        
        # æ·»åŠ å‰ç¶´
        st.write("ğŸ·ï¸ æ·»åŠ YOKOå‰ç¶´...")
        before_prefix = list(df.columns)[:5]
        df = df.add_prefix('YOKO: ')
        df.rename(columns={'YOKO: time_index': 'time_index'}, inplace=True)
        after_prefix = list(df.columns)[:5]
        
        st.write(f"  å‰ç¶´å‰: {before_prefix}")
        st.write(f"  å‰ç¶´å¾Œ: {after_prefix}")
        
        result_df = df.set_index('time_index')
        
        # å‰µå»ºå…ƒæ•¸æ“š
        file_size_kb = len(file_content.getvalue()) / 1024
        time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
        
        metadata = LogMetadata(
            filename=filename,
            log_type=self.log_type,
            rows=result_df.shape[0],
            columns=result_df.shape[1],
            time_range=time_range,
            file_size_kb=file_size_kb
        )
        
        st.write(f"ğŸ‰ YOKOGAWA v10.3.4 ç”¨æˆ¶æ•¸æ“šä¿®æ­£è§£æå®Œæˆï¼")
        st.write(f"ğŸ“Š æœ€çµ‚æ•¸æ“šå½¢ç‹€: {result_df.shape}")
        st.write(f"ğŸ·ï¸ æœ€çµ‚æ¬„ä½æ¨£æœ¬: {list(result_df.columns)[:8]}...")
        
        return LogData(result_df, metadata)

# =============================================================================
# 3. è§£æå™¨è¨»å†Šç³»çµ± (Parser Registry)
# =============================================================================

class ParserRegistry:
    """è§£æå™¨è¨»å†Šç³»çµ±"""
    
    def __init__(self):
        self.parsers: List[LogParser] = []
    
    def register(self, parser: LogParser):
        """è¨»å†Šè§£æå™¨"""
        self.parsers.append(parser)
    
    def parse_file(self, uploaded_file) -> Optional[LogData]:
        """è§£ææª”æ¡ˆï¼Œè‡ªå‹•é¸æ“‡åˆé©çš„è§£æå™¨"""
        filename = uploaded_file.name
        file_content = io.BytesIO(uploaded_file.getvalue())
        is_excel = '.xlsx' in filename.lower() or '.xls' in filename.lower()
        
        st.write(f"ğŸ” æª”æ¡ˆåˆ†æ: {filename} (Excel: {is_excel})")
        
        for parser in self.parsers:
            try:
                file_content.seek(0)
                if parser.can_parse(file_content, filename):
                    st.write(f"ğŸ¯ ä½¿ç”¨ {parser.log_type} è§£æå™¨")
                    file_content.seek(0)
                    result = parser.parse(file_content, filename)
                    if result is not None:
                        return result
            except Exception as e:
                st.write(f"âš ï¸ {parser.log_type} è§£æå™¨å¤±æ•—: {e}")
                continue
        
        return None

# =============================================================================
# 4. çµ±è¨ˆè¨ˆç®—å±¤ (Statistics Layer)
# =============================================================================

class StatisticsCalculator:
    """çµ±è¨ˆè¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate_gpumon_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—GPUMonçµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return None, None, None, None
        
        # GPUæº«åº¦çµ±è¨ˆ
        temp_stats = []
        temp_cols = [col for col in df.columns if 'Temperature' in col and 'GPU' in col]
        
        for col in temp_cols:
            temp_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(temp_data) > 0:
                temp_stats.append({
                    'Temperature Sensor': col.replace('GPU: ', ''),
                    'Max (Â°C)': f"{temp_data.max():.2f}",
                    'Min (Â°C)': f"{temp_data.min():.2f}",
                    'Avg (Â°C)': f"{temp_data.mean():.2f}"
                })
        
        temp_df = pd.DataFrame(temp_stats) if temp_stats else None
        
        # GPUåŠŸè€—çµ±è¨ˆ - åªé¡¯ç¤ºæŒ‡å®šçš„ä¸‰å€‹é …ç›®
        power_stats = []
        target_power_items = ['NVVDD', 'FBVDD', 'TGP']
        
        for target_item in target_power_items:
            matching_cols = [col for col in df.columns if target_item in col and ('Power' in col or 'TGP' in col)]
            
            for col in matching_cols:
                power_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(power_data) > 0:
                    display_name = col.replace('GPU: ', '')
                    if 'NVVDD' in col:
                        display_name = 'NVVDD Power'
                    elif 'FBVDD' in col:
                        display_name = 'FBVDD Power'
                    elif 'TGP' in col:
                        display_name = 'TGP (W)'
                    
                    power_stats.append({
                        'Power Rail': display_name,
                        'Max (W)': f"{power_data.max():.2f}",
                        'Min (W)': f"{power_data.min():.2f}",
                        'Avg (W)': f"{power_data.mean():.2f}"
                    })
                    break
        
        power_df = pd.DataFrame(power_stats) if power_stats else None
        
        # GPUé »ç‡çµ±è¨ˆ
        freq_stats = []
        freq_cols = [col for col in df.columns if 'Clock' in col and any(x in col for x in ['GPC', 'Memory'])]
        
        for col in freq_cols:
            freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(freq_data) > 0:
                freq_stats.append({
                    'Clock Domain': col.replace('GPU: ', ''),
                    'Max (MHz)': f"{freq_data.max():.0f}",
                    'Min (MHz)': f"{freq_data.min():.0f}",
                    'Avg (MHz)': f"{freq_data.mean():.0f}"
                })
        
        freq_df = pd.DataFrame(freq_stats) if freq_stats else None
        
        # GPUä½¿ç”¨ç‡çµ±è¨ˆ
        util_stats = []
        util_cols = [col for col in df.columns if 'Utilization' in col]
        
        for col in util_cols:
            util_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(util_data) > 0:
                util_stats.append({
                    'Utilization Type': col.replace('GPU: ', ''),
                    'Max (%)': f"{util_data.max():.1f}",
                    'Min (%)': f"{util_data.min():.1f}",
                    'Avg (%)': f"{util_data.mean():.1f}"
                })
        
        util_df = pd.DataFrame(util_stats) if util_stats else None
        
        return temp_df, power_df, freq_df, util_df
    
    @staticmethod
    def calculate_ptat_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—PTATçµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return None, None, None
        
        # CPU Core Frequency çµ±è¨ˆ
        freq_stats = []
        freq_cols = [col for col in df.columns if 'frequency' in col.lower() and 'core' in col.lower()]
        
        lfm_value = "N/A"
        hfm_value = "N/A"
        
        for col in df.columns:
            if 'lfm' in col.lower():
                lfm_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(lfm_data) > 0:
                    lfm_value = f"{lfm_data.iloc[0]:.0f} MHz"
            elif 'hfm' in col.lower():
                hfm_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(hfm_data) > 0:
                    hfm_value = f"{hfm_data.iloc[0]:.0f} MHz"
        
        if lfm_value == "N/A" or hfm_value == "N/A":
            all_freq_data = []
            for col in freq_cols:
                freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
                all_freq_data.extend(freq_data.tolist())
            
            if all_freq_data:
                if lfm_value == "N/A":
                    lfm_value = f"{min(all_freq_data):.0f} MHz (ä¼°ç®—)"
                if hfm_value == "N/A":
                    hfm_value = f"{max(all_freq_data):.0f} MHz (ä¼°ç®—)"
        
        for col in freq_cols:
            freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(freq_data) > 0:
                freq_stats.append({
                    'Core': col.replace('PTAT: ', ''),
                    'Max (MHz)': f"{freq_data.max():.0f}",
                    'Min (MHz)': f"{freq_data.min():.0f}",
                    'Avg (MHz)': f"{freq_data.mean():.0f}"
                })
        
        if freq_stats:
            freq_stats.append({
                'Core': '--- åƒè€ƒå€¼ ---',
                'Max (MHz)': '',
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
            freq_stats.append({
                'Core': 'LFM (Low Freq Mode)',
                'Max (MHz)': lfm_value,
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
            freq_stats.append({
                'Core': 'HFM (High Freq Mode)',
                'Max (MHz)': hfm_value,
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
        
        freq_df = pd.DataFrame(freq_stats) if freq_stats else None
        
        # Package Power çµ±è¨ˆ
        power_stats = []
        target_power_items = [
            ('IA', 'IA Power'),
            ('GT', 'GT Power'), 
            ('Rest of package', 'Rest of Package Power'),
            ('Package', 'Package Power')
        ]
        
        for search_term, display_name in target_power_items:
            matching_cols = []
            for col in df.columns:
                col_lower = col.lower()
                search_lower = search_term.lower()
                
                if search_term == 'IA':
                    if 'ia' in col_lower and 'power' in col_lower and 'via' not in col_lower:
                        matching_cols.append(col)
                elif search_term == 'GT':
                    if 'gt' in col_lower and 'power' in col_lower and 'tgp' not in col_lower:
                        matching_cols.append(col)
                elif search_term == 'Rest of package':
                    if 'rest' in col_lower and 'package' in col_lower and 'power' in col_lower:
                        matching_cols.append(col)
                elif search_term == 'Package':
                    if 'package' in col_lower and 'power' in col_lower and 'rest' not in col_lower:
                        matching_cols.append(col)
            
            if matching_cols:
                col = matching_cols[0]
                power_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(power_data) > 0:
                    power_stats.append({
                        'Power Type': display_name,
                        'Max (W)': f"{power_data.max():.2f}",
                        'Min (W)': f"{power_data.min():.2f}",
                        'Avg (W)': f"{power_data.mean():.2f}"
                    })
        
        power_df = pd.DataFrame(power_stats) if power_stats else None
        
        # MSR Package Temperature çµ±è¨ˆ
        temp_stats = []
        temp_cols = [col for col in df.columns if 'temperature' in col.lower() and 'package' in col.lower() and 'msr' in col.lower()]
        
        for col in temp_cols:
            temp_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(temp_data) > 0:
                temp_stats.append({
                    'Temperature Type': col.replace('PTAT: ', ''),
                    'Max (Â°C)': f"{temp_data.max():.2f}",
                    'Min (Â°C)': f"{temp_data.min():.2f}",
                    'Avg (Â°C)': f"{temp_data.mean():.2f}"
                })
        
        temp_df = pd.DataFrame(temp_stats) if temp_stats else None
        
        return freq_df, power_df, temp_df
    
    @staticmethod
    def calculate_temp_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—æº«åº¦çµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return pd.DataFrame()
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        temp_cols = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
        
        stats_data = []
        for col in temp_cols:
            y_data = pd.to_numeric(df[col], errors='coerce')
            if not y_data.isna().all():
                t_max = y_data.max()
                t_avg = y_data.mean()
                
                display_name = col
                if display_name.startswith('YOKO: '):
                    display_name = display_name.replace('YOKO: ', '')
                elif display_name.startswith('PTAT: '):
                    display_name = display_name.replace('PTAT: ', '')
                elif display_name.startswith('GPU: '):
                    display_name = display_name.replace('GPU: ', '')
                
                if display_name.lower() in ['sec', 'time', 'rt', 'date']:
                    continue
                
                stats_data.append({
                    'é€šé“åç¨±': display_name,
                    'Tmax (Â°C)': f"{t_max:.2f}" if pd.notna(t_max) else "N/A",
                    'Tavg (Â°C)': f"{t_avg:.2f}" if pd.notna(t_avg) else "N/A"
                })
        
        return pd.DataFrame(stats_data)

# =============================================================================
# 5. åœ–è¡¨ç”Ÿæˆå±¤ (Chart Generation Layer)
# =============================================================================

class ChartGenerator:
    """åœ–è¡¨ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_gpumon_chart(log_data: LogData, left_col: str, right_col: str, x_limits, left_y_limits=None, right_y_limits=None):
        """ç”ŸæˆGPUMonå°ˆç”¨åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty or not left_col or left_col not in df.columns:
            return None
        if right_col and right_col != 'None' and right_col not in df.columns:
            return None
        
        df_chart = df.copy()
        df_chart.loc[:, 'left_val'] = pd.to_numeric(df_chart[left_col], errors='coerce')
        if right_col and right_col != 'None':
            df_chart.loc[:, 'right_val'] = pd.to_numeric(df_chart[right_col], errors='coerce')
        
        fig, ax1 = plt.subplots(figsize=(10.2, 5.1))
        
        title = f'GPUMon: {left_col.replace("GPU: ", "")} {"& " + right_col.replace("GPU: ", "") if right_col and right_col != "None" else ""}'
        plt.title(title, fontsize=14, fontweight='bold')
        
        x_axis_seconds = df_chart.index.total_seconds()
        color = 'tab:orange'
        ax1.set_xlabel('Elapsed Time (seconds)', fontsize=11)
        ax1.set_ylabel(left_col.replace("GPU: ", ""), color=color, fontsize=11)
        ax1.plot(x_axis_seconds, df_chart['left_val'], color=color, linewidth=2)
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        
        if left_y_limits:
            ax1.set_ylim(left_y_limits)
        
        if right_col and right_col != 'None':
            ax2 = ax1.twinx()
            color = 'tab:green'
            ax2.set_ylabel(right_col.replace("GPU: ", ""), color=color, fontsize=11)
            ax2.plot(x_axis_seconds, df_chart['right_val'], color=color, linewidth=2)
            ax2.tick_params(axis='y', labelcolor=color)
            
            if right_y_limits:
                ax2.set_ylim(right_y_limits)
        
        if x_limits:
            ax1.set_xlim(x_limits)
        
        fig.tight_layout()
        return fig
    
    @staticmethod
    def generate_flexible_chart(log_data: LogData, left_col: str, right_col: str, x_limits, left_y_limits=None, right_y_limits=None):
        """ç”Ÿæˆéˆæ´»çš„é›™è»¸åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty or not left_col or left_col not in df.columns:
            return None
        if right_col and right_col != 'None' and right_col not in df.columns:
            return None
        
        df_chart = df.copy()
        df_chart.loc[:, 'left_val'] = pd.to_numeric(df_chart[left_col], errors='coerce')
        if right_col and right_col != 'None':
            df_chart.loc[:, 'right_val'] = pd.to_numeric(df_chart[right_col], errors='coerce')
        
        fig, ax1 = plt.subplots(figsize=(10.2, 5.1))
        plt.title(f'{left_col} {"& " + right_col if right_col and right_col != "None" else ""}', fontsize=14, fontweight='bold')
        
        x_axis_seconds = df_chart.index.total_seconds()
        color = 'tab:blue'
        ax1.set_xlabel('Elapsed Time (seconds)', fontsize=11)
        ax1.set_ylabel(left_col, color=color, fontsize=11)
        ax1.plot(x_axis_seconds, df_chart['left_val'], color=color, linewidth=1.5)
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        
        if left_y_limits:
            ax1.set_ylim(left_y_limits)
        
        if right_col and right_col != 'None':
            ax2 = ax1.twinx()
            color = 'tab:red'
            ax2.set_ylabel(right_col, color=color, fontsize=11)
            ax2.plot(x_axis_seconds, df_chart['right_val'], color=color, linewidth=1.5)
            ax2.tick_params(axis='y', labelcolor=color)
            
            if right_y_limits:
                ax2.set_ylim(right_y_limits)
        
        if x_limits:
            ax1.set_xlim(x_limits)
        
        fig.tight_layout()
        return fig
    
    @staticmethod
    def generate_yokogawa_temp_chart(log_data: LogData, x_limits=None, y_limits=None):
        """æ”¹é€²ç‰ˆYOKOGAWAæº«åº¦åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty:
            return None
        
        fig, ax = plt.subplots(figsize=(10.2, 5.1))
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        cols_to_plot = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
        
        max_channels = 15
        if len(cols_to_plot) > max_channels:
            cols_to_plot = cols_to_plot[:max_channels]
        
        for col in cols_to_plot:
            y_data = pd.to_numeric(df[col], errors='coerce')
            if not y_data.isna().all():
                display_name = col.replace('YOKO: ', '') if col.startswith('YOKO: ') else col
                ax.plot(df.index.total_seconds(), y_data, label=display_name, linewidth=1)
        
        ax.set_title("YOKOGAWA All Channel Temperature Plot", fontsize=14, fontweight='bold')
        ax.set_xlabel("Elapsed Time (seconds)", fontsize=11)
        ax.set_ylabel("Temperature (Â°C)", fontsize=11)
        ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        ax.legend(title="Channels", bbox_to_anchor=(1.04, 1), loc="upper left", fontsize=7)
        
        if x_limits:
            ax.set_xlim(x_limits)
        
        if y_limits:
            ax.set_ylim(y_limits)
        
        fig.tight_layout()
        return fig

# =============================================================================
# 6. UIæ¸²æŸ“å±¤ (UI Rendering Layer)
# =============================================================================

class GPUMonRenderer:
    """GPUMon UIæ¸²æŸ“å™¨"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render_controls(self):
        """æ¸²æŸ“æ§åˆ¶é¢æ¿"""
        st.sidebar.markdown("### âš™ï¸ GPUMon åœ–è¡¨è¨­å®š")
        
        numeric_columns = self.log_data.numeric_columns
        if not numeric_columns:
            return None, None, None, None, None
        
        st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
        
        default_left_index = 0
        for i, col in enumerate(numeric_columns):
            if 'Temperature GPU' in col and '(C)' in col:
                default_left_index = i
                break
        
        left_y_axis = st.sidebar.selectbox(
            "ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", 
            options=numeric_columns, 
            index=default_left_index
        )
        
        right_y_axis_options = ['None'] + numeric_columns
        default_right_index = 0
        for i, col in enumerate(right_y_axis_options):
            if 'TGP' in col and '(W)' in col:
                default_right_index = i
                break
        
        right_y_axis = st.sidebar.selectbox(
            "ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", 
            options=right_y_axis_options, 
            index=default_right_index
        )
        
        st.sidebar.markdown("#### â±ï¸ æ™‚é–“ç¯„åœè¨­å®š")
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider(
            "é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)",
            min_value=time_min,
            max_value=time_max,
            value=(time_min, time_max),
            step=1.0
        )
        
        st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
        
        left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶")
        left_y_range = None
        if left_y_range_enabled:
            col1, col2 = st.sidebar.columns(2)
            with col1:
                left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key="left_y_min")
            with col2:
                left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key="left_y_max")
            left_y_range = (left_y_min, left_y_max)
        
        right_y_range = None
        if right_y_axis and right_y_axis != 'None':
            right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶")
            if right_y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key="right_y_min")
                with col2:
                    right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key="right_y_max")
                right_y_range = (right_y_min, right_y_max)
        
        return left_y_axis, right_y_axis, x_range, left_y_range, right_y_range
    
    def render_chart(self, left_col, right_col, x_range, left_y_range, right_y_range):
        """æ¸²æŸ“åœ–è¡¨"""
        st.markdown("### ğŸ“Š GPUMon æ€§èƒ½ç›£æ§åœ–è¡¨")
        
        chart = self.chart_gen.generate_gpumon_chart(
            self.log_data, left_col, right_col, x_range, left_y_range, right_y_range
        )
        if chart:
            st.pyplot(chart)
        else:
            st.warning("ç„¡æ³•ç”Ÿæˆåœ–è¡¨ï¼Œè«‹æª¢æŸ¥åƒæ•¸è¨­å®š")
    
    def render_statistics(self, x_range):
        """æ¸²æŸ“çµ±è¨ˆæ•¸æ“š"""
        st.markdown("### ğŸ“ˆ GPUMon çµ±è¨ˆæ•¸æ“š")
        
        temp_stats, power_stats, freq_stats, util_stats = self.stats_calc.calculate_gpumon_stats(
            self.log_data, x_range
        )
        
        if temp_stats is not None and not temp_stats.empty:
            st.markdown("#### ğŸŒ¡ï¸ GPU æº«åº¦çµ±è¨ˆ")
            st.dataframe(temp_stats, use_container_width=True, hide_index=True)
        
        if power_stats is not None and not power_stats.empty:
            st.markdown("#### ğŸ”‹ GPU åŠŸè€—çµ±è¨ˆ")
            st.dataframe(power_stats, use_container_width=True, hide_index=True)
        
        if freq_stats is not None and not freq_stats.empty:
            st.markdown("#### âš¡ GPU é »ç‡çµ±è¨ˆ")
            st.dataframe(freq_stats, use_container_width=True, hide_index=True)
        
        if util_stats is not None and not util_stats.empty:
            st.markdown("#### ğŸ“Š GPU ä½¿ç”¨ç‡çµ±è¨ˆ")
            st.dataframe(util_stats, use_container_width=True, hide_index=True)
    
    def render(self):
        """æ¸²æŸ“å®Œæ•´UI"""
        st.markdown("""
        <div class="gpumon-box">
            <h4>ğŸ® GPUMon Log æˆåŠŸè§£æï¼</h4>
            <p>å·²è­˜åˆ¥ç‚ºGPUç›£æ§æ•¸æ“šï¼ŒåŒ…å«æº«åº¦ã€åŠŸè€—ã€é »ç‡ç­‰æŒ‡æ¨™</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        left_col, right_col, x_range, left_y_range, right_y_range = self.render_controls()
        
        if left_col:
            self.render_chart(left_col, right_col, x_range, left_y_range, right_y_range)
            self.render_statistics(x_range)

class PTATRenderer:
    """PTAT UIæ¸²æŸ“å™¨"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render_controls(self):
        """æ¸²æŸ“æ§åˆ¶é¢æ¿"""
        st.sidebar.markdown("### âš™ï¸ PTAT åœ–è¡¨è¨­å®š")
        
        numeric_columns = self.log_data.numeric_columns
        if not numeric_columns:
            return None, None, None, None, None
        
        st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
        
        default_left_index = 0
        for i, col in enumerate(numeric_columns):
            if 'MSR' in col and 'Package' in col and 'Temperature' in col:
                default_left_index = i
                break
        
        left_y_axis = st.sidebar.selectbox("ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=default_left_index)
        
        right_y_axis_options = ['None'] + numeric_columns
        default_right_index = 0
        for i, col in enumerate(right_y_axis_options):
            if 'Package' in col and 'Power' in col:
                default_right_index = i
                break
        
        right_y_axis = st.sidebar.selectbox("ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", options=right_y_axis_options, index=default_right_index)
        
        st.sidebar.markdown("#### â±ï¸ æ™‚é–“ç¯„åœè¨­å®š")
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", min_value=time_min, max_value=time_max, value=(time_min, time_max), step=1.0)
        
        st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
        
        left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key="ptat_left_y")
        left_y_range = None
        if left_y_range_enabled:
            col1, col2 = st.sidebar.columns(2)
            with col1:
                left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key="ptat_left_y_min")
            with col2:
                left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key="ptat_left_y_max")
            left_y_range = (left_y_min, left_y_max)
        
        right_y_range = None
        if right_y_axis and right_y_axis != 'None':
            right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key="ptat_right_y")
            if right_y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key="ptat_right_y_min")
                with col2:
                    right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key="ptat_right_y_max")
                right_y_range = (right_y_min, right_y_max)
        
        return left_y_axis, right_y_axis, x_range, left_y_range, right_y_range
    
    def render(self):
        """æ¸²æŸ“å®Œæ•´UI"""
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ–¥ï¸ PTAT Log æˆåŠŸè§£æï¼</h4>
            <p>å·²è­˜åˆ¥ç‚ºCPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ŒåŒ…å«é »ç‡ã€åŠŸè€—ã€æº«åº¦ç­‰æŒ‡æ¨™</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        left_y_axis, right_y_axis, x_range, left_y_range, right_y_range = self.render_controls()
        
        if left_y_axis:
            st.markdown("### ğŸ“Š PTAT CPU æ€§èƒ½ç›£æ§åœ–è¡¨")
            chart = self.chart_gen.generate_flexible_chart(self.log_data, left_y_axis, right_y_axis, x_range, left_y_range, right_y_range)
            if chart:
                st.pyplot(chart)
            
            st.markdown("### ğŸ“ˆ PTAT çµ±è¨ˆæ•¸æ“š")
            freq_stats, power_stats, temp_stats = self.stats_calc.calculate_ptat_stats(self.log_data, x_range)
            
            if freq_stats is not None and not freq_stats.empty:
                st.markdown("#### âš¡ CPU é »ç‡çµ±è¨ˆ")
                st.dataframe(freq_stats, use_container_width=True, hide_index=True)
            
            if power_stats is not None and not power_stats.empty:
                st.markdown("#### ğŸ”‹ Package åŠŸè€—çµ±è¨ˆ")
                st.dataframe(power_stats, use_container_width=True, hide_index=True)
            
            if temp_stats is not None and not temp_stats.empty:
                st.markdown("#### ğŸŒ¡ï¸ Package æº«åº¦çµ±è¨ˆ")
                st.dataframe(temp_stats, use_container_width=True, hide_index=True)

class YokogawaRenderer:
    """YOKOGAWA UIæ¸²æŸ“å™¨"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render(self):
        """æ¸²æŸ“å®Œæ•´UI"""
        st.markdown("""
        <div class="success-box">
            <h4>ğŸ“Š YOKOGAWA Log æˆåŠŸè§£æï¼(v10.3.5 ç°¡æ½”ç•Œé¢ç‰ˆ)</h4>
            <p>å·²è­˜åˆ¥ç‚ºæº«åº¦è¨˜éŒ„å„€æ•¸æ“šï¼Œæ­£ç¢ºè­˜åˆ¥ç”¨æˆ¶æ¨™ç±¤ï¼Œè©³ç´°æ—¥èªŒå¯æ‘ºç–ŠæŸ¥çœ‹ï¼Œç•Œé¢ç°¡æ½”æ¸…çˆ½</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        st.sidebar.markdown("### âš™ï¸ YOKOGAWA åœ–è¡¨è¨­å®š")
        chart_mode = st.sidebar.radio("ğŸ“ˆ åœ–è¡¨æ¨¡å¼", ["å…¨é€šé“æº«åº¦åœ–", "è‡ªå®šç¾©é›™è»¸åœ–"])
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", min_value=time_min, max_value=time_max, value=(time_min, time_max), step=1.0)
        
        if chart_mode == "å…¨é€šé“æº«åº¦åœ–":
            st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
            y_range_enabled = st.sidebar.checkbox("å•Ÿç”¨Yè»¸ç¯„åœé™åˆ¶")
            y_range = None
            if y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    y_min = st.number_input("Yè»¸æœ€å°å€¼", value=0.0, key="yoko_single_y_min")
                with col2:
                    y_max = st.number_input("Yè»¸æœ€å¤§å€¼", value=100.0, key="yoko_single_y_max")
                y_range = (y_min, y_max)
            
            st.markdown("### ğŸ“Š YOKOGAWA å…¨é€šé“æº«åº¦åœ–è¡¨")
            chart = self.chart_gen.generate_yokogawa_temp_chart(self.log_data, x_range, y_range)
            if chart:
                st.pyplot(chart)
        
        else:
            numeric_columns = self.log_data.numeric_columns
            if numeric_columns:
                st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
                left_y_axis = st.sidebar.selectbox("ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=0)
                right_y_axis_options = ['None'] + numeric_columns
                right_y_axis = st.sidebar.selectbox("ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", options=right_y_axis_options, index=0)
                
                st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
                
                left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key="yoko_left_y")
                left_y_range = None
                if left_y_range_enabled:
                    col1, col2 = st.sidebar.columns(2)
                    with col1:
                        left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key="yoko_left_y_min")
                    with col2:
                        left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key="yoko_left_y_max")
                    left_y_range = (left_y_min, left_y_max)
                
                right_y_range = None
                if right_y_axis and right_y_axis != 'None':
                    right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key="yoko_right_y")
                    if right_y_range_enabled:
                        col1, col2 = st.sidebar.columns(2)
                        with col1:
                            right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key="yoko_right_y_min")
                        with col2:
                            right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key="yoko_right_y_max")
                        right_y_range = (right_y_min, right_y_max)
                
                st.markdown("### ğŸ“Š YOKOGAWA è‡ªå®šç¾©åœ–è¡¨")
                chart = self.chart_gen.generate_flexible_chart(self.log_data, left_y_axis, right_y_axis, x_range, left_y_range, right_y_range)
                if chart:
                    st.pyplot(chart)
        
        st.markdown("### ğŸ“ˆ æº«åº¦çµ±è¨ˆæ•¸æ“š")
        temp_stats = self.stats_calc.calculate_temp_stats(self.log_data, x_range)
        if not temp_stats.empty:
            st.dataframe(temp_stats, use_container_width=True, hide_index=True)

# =============================================================================
# 7. UIå·¥å»  (UI Factory)
# =============================================================================

class RendererFactory:
    """UIæ¸²æŸ“å™¨å·¥å» """
    
    @staticmethod
    def create_renderer(log_data: LogData):
        """æ ¹æ“šlogé¡å‹å‰µå»ºå°æ‡‰çš„æ¸²æŸ“å™¨"""
        log_type = log_data.metadata.log_type
        
        if log_type == "GPUMon Log":
            return GPUMonRenderer(log_data)
        elif log_type == "PTAT Log":
            return PTATRenderer(log_data)
        elif log_type == "YOKOGAWA Log":
            return YokogawaRenderer(log_data)
        else:
            return None

# =============================================================================
# 8. ä¸»æ‡‰ç”¨ç¨‹å¼ (Main Application)
# =============================================================================

def display_version_info():
    """é¡¯ç¤ºç‰ˆæœ¬è³‡è¨Š"""
    with st.expander("ğŸ“‹ ç‰ˆæœ¬è³‡è¨Š", expanded=False):
        st.markdown(f"""
        **ç•¶å‰ç‰ˆæœ¬ï¼š{VERSION}** | **ç™¼å¸ƒæ—¥æœŸï¼š{VERSION_DATE}**
        
        ### ğŸ†• v10.3.5 Dynamic Keyword Search - Clean UI æ›´æ–°å…§å®¹ï¼š
        - ğŸ¨ **ç°¡æ½”ç•Œé¢è¨­è¨ˆ** - è©³ç´°è§£ææ—¥èªŒéš±è—åœ¨ä¸‹æ‹‰é¸å–®ä¸­ï¼Œç•Œé¢æ›´æ¸…çˆ½
        - ğŸ“Š **é‡è¦ä¿¡æ¯çªå‡º** - ä¸»è¦çµæœæ¸…æ™°é¡¯ç¤ºï¼Œè©³ç´°éç¨‹å¯é¸æ“‡æŸ¥çœ‹
        - ğŸ” **æ‘ºç–Šå¼èª¿è©¦å€** - æ–‡ä»¶åˆ†æã€Tagæœç´¢ã€é‡å‘½åè¨ˆåŠƒéƒ½å¯æ‘ºç–Š
        - ğŸ“ˆ **çµ±è¨ˆä¿¡æ¯è¦–è¦ºåŒ–** - ä½¿ç”¨å¡ç‰‡å¼æŒ‡æ¨™é¡¯ç¤ºé‡å‘½åçµ±è¨ˆ
        - ğŸ¯ **ä¿æŒå®Œæ•´åŠŸèƒ½** - æ‰€æœ‰èª¿è©¦ä¿¡æ¯ä¾ç„¶å®Œæ•´ï¼Œåªæ˜¯ç•Œé¢æ›´æ•´æ½”
        - ğŸ·ï¸ **ç”¨æˆ¶æ¨™ç±¤è­˜åˆ¥** - ç¹¼çºŒæ­£ç¢ºè­˜åˆ¥ CPU_Tc, U5, U19 ç­‰ç”¨æˆ¶æ¨™ç±¤
        - ğŸ›¡ï¸ **é—œéµæ¬„ä½ä¿è­·** - Dateã€Timeç­‰é‡è¦æ¬„ä½æ°¸ä¸è¢«é‡å‘½å
        
        ### ğŸ”„ è§£æç­–ç•¥å°æ¯”ï¼š
        - **v10.2**: å›ºå®šè¡Œè™Ÿ [29, 28, 30, 27] â†’ éœ€è¦å®Œæ•´æª”æ¡ˆ
        - **v10.3.5**: ç°¡æ½”ç•Œé¢ç‰ˆ â†’ ä¿æŒå…¨åŠŸèƒ½ï¼Œè©³ç´°æ—¥èªŒæ‘ºç–Šéš±è—ï¼Œç•Œé¢æ›´æ¸…çˆ½
        
        ### ğŸ—ï¸ æŠ€è¡“ç‰¹é»ï¼š
        - **ä¸‰éšæ®µæœç´¢**: é—œéµå­— â†’ çµæ§‹ â†’ é è¨­å€¼
        - **æ™ºèƒ½é‡å‘½å**: Tagå„ªå…ˆ â†’ CHå‚™é¸ â†’ åŸåä¿ç•™
        - **å‹•æ…‹é©æ‡‰**: æ“´å¤§æœç´¢ç¯„åœï¼Œæé«˜è­˜åˆ¥ç‡
        - **è©³ç´°æ—¥èªŒ**: å®Œæ•´çš„è§£æéç¨‹è¿½è¹¤
        
        ---
        ğŸ’¡ **ä½¿ç”¨å»ºè­°ï¼š** å®Œæ•´æª”æ¡ˆæ•ˆæœæœ€ä½³ï¼Œéƒ¨åˆ†æª”æ¡ˆäº¦å¯ä½¿ç”¨ï¼
        """)

def main():
    """ä¸»ç¨‹å¼ - v10.3.5 Dynamic Keyword Search - Clean UI"""
    st.set_page_config(
        page_title="æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å°",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # CSSæ¨£å¼
    st.markdown("""
    <style>
        .main-header {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            padding: 1.5rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
            color: white;
        }
        .success-box {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .info-box {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            color: #0c5460;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .gpumon-box {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .stMetric {
            background-color: #f8f9fa;
            padding: 0.5rem;
            border-radius: 0.25rem;
            border: 1px solid #dee2e6;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # æ¨™é¡Œ
    st.markdown(f"""
    <div class="main-header">
        <h1>ğŸ“Š æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å°</h1>
        <p>æ™ºèƒ½è§£æ YOKOGAWAã€PTATã€GPUMon Log æ–‡ä»¶ï¼Œæ”¯æ´å‹•æ…‹é—œéµå­—æœç´¢</p>
        <p><strong>{VERSION}</strong> | {VERSION_DATE}</p>
    </div>
    """, unsafe_allow_html=True)
    
    display_version_info()
    
    # åˆå§‹åŒ–è§£æå™¨è¨»å†Šç³»çµ±
    parser_registry = ParserRegistry()
    parser_registry.register(GPUMonParser())
    parser_registry.register(PTATParser())
    parser_registry.register(YokogawaParser())  # å…œåº•è§£æå™¨
    
    # å´é‚Šæ¬„
    st.sidebar.markdown("### ğŸ›ï¸ æ§åˆ¶é¢æ¿")
    st.sidebar.markdown("---")
    
    uploaded_files = st.sidebar.file_uploader(
        "ğŸ“ ä¸Šå‚³Log File (å¯å¤šé¸)", 
        type=['csv', 'xlsx'], 
        accept_multiple_files=True,
        help="v10.3.5 æ”¯æ´ YOKOGAWA å®Œæ•´/éƒ¨åˆ†æª”æ¡ˆã€PTAT CSVã€GPUMon CSV"
    )
    
    # é¡¯ç¤ºè¨ªå•è¨ˆæ•¸å™¨
    display_visit_counter()
    
    if uploaded_files:
        # é¡¯ç¤ºä¸Šå‚³æª”æ¡ˆè³‡è¨Š
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ“‚ å·²ä¸Šå‚³æª”æ¡ˆ")
        for i, file in enumerate(uploaded_files, 1):
            file_size = len(file.getvalue()) / 1024
            st.sidebar.markdown(f"**{i}.** `{file.name}` ({file_size:.1f} KB)")
        
        st.sidebar.markdown("---")
        
        # è§£ææª”æ¡ˆ
        st.markdown("### ğŸ” v10.3.5 ç°¡æ½”è§£æç•Œé¢")
        
        log_data_list = []
        for uploaded_file in uploaded_files:
            log_data = parser_registry.parse_file(uploaded_file)
            if log_data:
                log_data_list.append(log_data)
        
        if not log_data_list:
            st.error("âŒ ç„¡æ³•è§£æä»»ä½•æª”æ¡ˆ")
            return
        
        # æ ¹æ“šæª”æ¡ˆæ•¸é‡å’Œé¡å‹æ±ºå®šUIæ¨¡å¼
        if len(log_data_list) == 1:
            log_data = log_data_list[0]
            renderer = RendererFactory.create_renderer(log_data)
            
            if renderer:
                renderer.render()
            else:
                st.error(f"ä¸æ”¯æ´çš„Logé¡å‹: {log_data.metadata.log_type}")
        
        else:
            st.info("ğŸ“Š å¤šæª”æ¡ˆæ¨¡å¼ï¼Œä½¿ç”¨åŸºæœ¬åˆ†æåŠŸèƒ½")
            
            # å¤šæª”æ¡ˆåˆä½µé‚è¼¯
            try:
                combined_df = pd.concat([log_data.df for log_data in log_data_list], axis=1)
                
                combined_metadata = LogMetadata(
                    filename="åˆä½µæª”æ¡ˆ",
                    log_type="æ··åˆé¡å‹",
                    rows=combined_df.shape[0],
                    columns=combined_df.shape[1],
                    time_range=f"{combined_df.index.min()} åˆ° {combined_df.index.max()}",
                    file_size_kb=sum(log_data.metadata.file_size_kb for log_data in log_data_list)
                )
                
                combined_log_data = LogData(combined_df, combined_metadata)
                
                st.success(f"âœ… åˆä½µæ•¸æ“šè¼‰å…¥æˆåŠŸï¼š{combined_log_data.metadata.rows} è¡Œ Ã— {combined_log_data.metadata.columns} åˆ—")
                
                numeric_columns = combined_log_data.numeric_columns
                if numeric_columns:
                    st.sidebar.markdown("### âš™ï¸ åœ–è¡¨è¨­å®š")
                    left_y_axis = st.sidebar.selectbox("ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=0)
                    right_y_axis_options = ['None'] + numeric_columns
                    right_y_axis = st.sidebar.selectbox("ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", options=right_y_axis_options, index=0)
                    
                    time_min, time_max = combined_log_data.get_time_range()
                    x_range = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", min_value=time_min, max_value=time_max, value=(time_min, time_max), step=1.0)
                    
                    # Yè»¸ç¯„åœæ§åˆ¶
                    st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
                    
                    # å·¦å´Yè»¸ç¯„åœè¨­å®š
                    left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key="combined_left_y")
                    left_y_range = None
                    if left_y_range_enabled:
                        col1, col2 = st.sidebar.columns(2)
                        with col1:
                            left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key="combined_left_y_min")
                        with col2:
                            left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key="combined_left_y_max")
                        left_y_range = (left_y_min, left_y_max)
                    
                    # å³å´Yè»¸ç¯„åœè¨­å®š
                    right_y_range = None
                    if right_y_axis and right_y_axis != 'None':
                        right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key="combined_right_y")
                        if right_y_range_enabled:
                            col1, col2 = st.sidebar.columns(2)
                            with col1:
                                right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key="combined_right_y_min")
                            with col2:
                                right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key="combined_right_y_max")
                            right_y_range = (right_y_min, right_y_max)
                    
                    st.markdown("### ğŸ“Š ç¶œåˆæ•¸æ“šåœ–è¡¨")
                    chart_gen = ChartGenerator()
                    chart = chart_gen.generate_flexible_chart(combined_log_data, left_y_axis, right_y_axis, x_range, left_y_range, right_y_range)
                    if chart:
                        st.pyplot(chart)
                    
                    # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆæ•¸æ“š
                    st.markdown("### ğŸ“ˆ åŸºæœ¬çµ±è¨ˆæ•¸æ“š")
                    stats_calc = StatisticsCalculator()
                    temp_stats = stats_calc.calculate_temp_stats(combined_log_data, x_range)
                    if not temp_stats.empty:
                        st.dataframe(temp_stats, use_container_width=True, hide_index=True)
            
            except Exception as e:
                st.error(f"åˆä½µæ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
    
    else:
        st.info("ğŸš€ **é–‹å§‹ä½¿ç”¨** - è«‹åœ¨å·¦å´ä¸Šå‚³æ‚¨çš„ Log æ–‡ä»¶é€²è¡Œåˆ†æ")
        
        st.markdown("""
        ### ğŸ“‹ æ”¯æ´çš„æª”æ¡ˆæ ¼å¼
        
        - **ğŸ® GPUMon CSV** - GPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ˆæº«åº¦ã€åŠŸè€—ã€é »ç‡ã€ä½¿ç”¨ç‡ï¼‰
        - **ğŸ–¥ï¸ PTAT CSV** - CPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ˆé »ç‡ã€åŠŸè€—ã€æº«åº¦ï¼‰
        - **ğŸ“Š YOKOGAWA Excel/CSV** - å¤šé€šé“æº«åº¦è¨˜éŒ„å„€æ•¸æ“šï¼ˆå®Œæ•´/éƒ¨åˆ†æª”æ¡ˆï¼‰
        
        ### ğŸ” v10.3 Dynamic Keyword Search æ–°åŠŸèƒ½
        
        - **ğŸ” å‹•æ…‹é—œéµå­—æœç´¢** - æ™ºèƒ½è­˜åˆ¥Headerè¡Œï¼Œä¸ä¾è³´å›ºå®šä½ç½®
        - **ğŸ“Š å®Œæ•´/éƒ¨åˆ†æª”æ¡ˆæ”¯æ´** - å®Œæ•´æª”æ¡ˆäº«å—æ™ºèƒ½é‡å‘½åï¼Œéƒ¨åˆ†æª”æ¡ˆäº¦å¯è§£æ
        - **ğŸ·ï¸ æ™ºèƒ½CH/Tagè­˜åˆ¥** - è‡ªå‹•æ‰¾åˆ°é€šé“æ¨™ç±¤ä¿¡æ¯ä¸¦é‡å‘½å
        - **ğŸ¯ ä¸‰éšæ®µå®¹éŒ¯** - é—œéµå­— â†’ çµæ§‹ â†’ é è¨­å€¼é€å±¤æœç´¢
        - **ğŸŒ å¤šèªè¨€é—œéµè©** - æ”¯æ´ä¸­è‹±æ–‡æ™‚é–“ç›¸é—œé—œéµè©
        - **ğŸ“ å…¨é¢Yè»¸æ§åˆ¶** - æ‰€æœ‰Logé¡å‹éƒ½æ”¯æ´é›™è»¸ç¯„åœèª¿æ•´
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè­°
        
        #### ğŸ“ **YOKOGAWA æª”æ¡ˆæœ€ä½³å¯¦è¸**
        
        **ğŸ¥‡ æ¨è–¦ï¼šå®Œæ•´æª”æ¡ˆ**
        ```
        âœ… åŒ…å«å®Œæ•´çš„æª”æ¡ˆçµæ§‹
        âœ… è‡ªå‹•è­˜åˆ¥CHå’ŒTagè¡Œ
        âœ… æ™ºèƒ½æ¬„ä½é‡å‘½å
        âœ… æœ€ä½³è§£ææ•ˆæœ
        ```
        
        **ğŸ¥ˆ å¯ç”¨ï¼šéƒ¨åˆ†æª”æ¡ˆ**
        ```
        âœ… åƒ…åŒ…å«æ•¸æ“šå’Œæ™‚é–“æ¬„ä½
        âœ… åŸºæœ¬åœ–è¡¨åŠŸèƒ½æ­£å¸¸
        âš ï¸ ç„¡æ³•é€²è¡Œæ¬„ä½é‡å‘½å
        ğŸ’¡ ä»å¯é€²è¡Œæ•¸æ“šåˆ†æ
        ```
        
        ### ğŸ”§ v10.3.5 æŠ€è¡“ç‰¹é»
        
        - **ç°¡æ½”ç•Œé¢è¨­è¨ˆ** - ä½¿ç”¨Streamlit expanderå°‡è©³ç´°æ—¥èªŒæ‘ºç–Šï¼Œä¸»ç•Œé¢æ›´æ¸…çˆ½
        - **è¦–è¦ºåŒ–çµ±è¨ˆä¿¡æ¯** - ä½¿ç”¨st.metricå¡ç‰‡å¼é¡¯ç¤ºé‡å‘½åçµ±è¨ˆï¼Œä¸€ç›®äº†ç„¶
        - **ç”¨æˆ¶æ•¸æ“šå°ˆç”¨å„ªåŒ–** - é‡å°å¯¦éš›ç”¨æˆ¶æ–‡ä»¶çµæ§‹(CPU_Tc, U5, U19ç­‰)å„ªåŒ–è­˜åˆ¥é‚è¼¯
        - **æ™ºèƒ½æ¨™ç±¤è­˜åˆ¥ç®—æ³•** - æ”¯æ´å¤šç¨®ç”¨æˆ¶æ¨™ç±¤æ ¼å¼ï¼šå­—æ¯+æ•¸å­—ã€ä¸‹åŠƒç·šã€çŸ­ç·¨è™Ÿ
        - **æœ€ä½³è¡Œé¸æ“‡ç­–ç•¥** - è‡ªå‹•é¸æ“‡æ¨™ç±¤æ•¸é‡æœ€å¤šçš„è¡Œï¼Œç¢ºä¿æ‰¾åˆ°çœŸæ­£çš„Tagè¡Œ
        - **å®Œæ•´èª¿è©¦åŠŸèƒ½** - æ‰€æœ‰èª¿è©¦ä¿¡æ¯ä¾ç„¶å®Œæ•´ï¼Œåªæ˜¯ç•Œé¢çµ„ç¹”æ›´å¥½
        - **ç”¨æˆ¶éœ€æ±‚å°å‘** - å®Œå…¨æŒ‰ç…§ã€ŒTagå„ªå…ˆï¼ŒCHå‚™é¸ã€çš„å‘½åé‚è¼¯è¨­è¨ˆ
        - **é—œéµæ¬„ä½ä¿è­·** - Dateã€Timeç­‰æ¬„ä½æ°¸ä¸è¢«é‡å‘½å
        """)

if __name__ == "__main__":
    main()
