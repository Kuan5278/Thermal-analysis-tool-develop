# universal_analysis_platform_v7_2_yokogawa_time_range.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
import re

# --- å­æ¨¡çµ„ï¼šPTAT Log è§£æå™¨ (ç©©å®šç‰ˆ) ---
def parse_ptat(file_content):
    try:
        df = pd.read_csv(file_content, header=0, thousands=',', low_memory=False)
        df.columns = df.columns.str.strip()
        time_column = 'Time'
        if time_column not in df.columns: return None, "PTAT Logä¸­æ‰¾ä¸åˆ° 'Time' æ¬„ä½"
        time_series = df[time_column].astype(str).str.strip()
        time_series_cleaned = time_series.str.replace(r':(\d{3})$', r'.\1', regex=True)
        datetime_series = pd.to_datetime(time_series_cleaned, format='%H:%M:%S.%f', errors='coerce')
        valid_times_mask = datetime_series.notna()
        df = df[valid_times_mask].copy()
        if df.empty: return None, "PTAT Logæ™‚é–“æ ¼å¼ç„¡æ³•è§£æ"
        valid_datetimes = datetime_series[valid_times_mask]
        df['time_index'] = valid_datetimes - valid_datetimes.iloc[0]
        df = df.add_prefix('PTAT: ')
        df.rename(columns={'PTAT: time_index': 'time_index'}, inplace=True)
        return df.set_index('time_index'), "PTAT Log"
    except Exception as e:
        return None, f"è§£æPTAT Logæ™‚å‡ºéŒ¯: {e}"

# --- å­æ¨¡çµ„ï¼šYOKOGAWA Log è§£æå™¨ (å°ˆç”¨ä¿®æ­£ç‰ˆ) ---
def parse_yokogawa(file_content, is_excel=False):
    try:
        read_func = pd.read_excel if is_excel else pd.read_csv
        
        # æ ¹æ“šä½ çš„æ–‡ä»¶çµæ§‹ï¼Œè¡¨é ­åœ¨ç¬¬30è¡Œï¼ˆpandasçš„header=29ï¼‰
        if is_excel:
            # é¦–å…ˆå˜—è©¦ç¬¬30è¡Œä½œç‚ºè¡¨é ­ï¼ˆé€™æ˜¯ä½ æ–‡ä»¶çš„å¯¦éš›çµæ§‹ï¼‰
            possible_headers = [29, 28, 30, 27]  # 29å°æ‡‰ç¬¬30è¡Œ
        else:
            possible_headers = [0, 1, 2]
            
        df = None
        found_time_col = None
        successful_header = None
        
        for header_row in possible_headers:
            try:
                file_content.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é‡
                df = read_func(file_content, header=header_row, thousands=',')
                
                # æ¸…ç†æ¬„ä½åç¨±
                df.columns = df.columns.str.strip()
                
                # Debug ä¿¡æ¯
                st.write(f"å˜—è©¦ header={header_row}, æ¬„ä½: {list(df.columns[:10])}")  # åªé¡¯ç¤ºå‰10å€‹æ¬„ä½
                
                # æª¢æŸ¥å¯èƒ½çš„æ™‚é–“æ¬„ä½åç¨±
                time_candidates = ['Time', 'TIME', 'time', 'Date', 'DATE', 'date', 
                                 'DateTime', 'DATETIME', 'datetime', 'æ™‚é–“', 'æ—¥æœŸæ™‚é–“',
                                 'Timestamp', 'TIMESTAMP', 'timestamp']
                
                for candidate in time_candidates:
                    if candidate in df.columns:
                        found_time_col = candidate
                        successful_header = header_row
                        break
                
                if found_time_col:
                    st.success(f"æˆåŠŸæ‰¾åˆ°æ™‚é–“æ¬„ä½ '{found_time_col}' åœ¨ header={header_row}")
                    break
                    
            except Exception as e:
                st.warning(f"Header row {header_row} å¤±æ•—: {e}")
                continue
        
        if df is None or found_time_col is None:
            error_msg = f"YOKOGAWA Logä¸­æ‰¾ä¸åˆ°æ™‚é–“æ¬„ä½ã€‚"
            if df is not None:
                error_msg += f" å¯ç”¨æ¬„ä½: {list(df.columns)[:15]}"  # é™åˆ¶é¡¯ç¤ºæ¬„ä½æ•¸é‡
            return None, error_msg
        
        time_column = found_time_col
        st.info(f"ä½¿ç”¨æ™‚é–“æ¬„ä½: {time_column}, è¡¨é ­è¡Œ: {successful_header}")
        
        # é¡¯ç¤ºå‰å¹¾ç­†æ™‚é–“æ•¸æ“šä¾›debug
        st.write(f"æ™‚é–“æ¬„ä½å‰5ç­†æ•¸æ“š: {df[time_column].head().tolist()}")
        
        # è™•ç†æ™‚é–“æ•¸æ“š
        time_series = df[time_column].astype(str).str.strip()
        
        # å°ˆé–€è™•ç† HH:MM:SS æ ¼å¼ï¼ˆä½ çš„æ–‡ä»¶æ ¼å¼ï¼‰
        try:
            # å…ˆå˜—è©¦ç›´æ¥è½‰ç‚º timedeltaï¼ˆé©ç”¨æ–¼ç´”æ™‚é–“æ ¼å¼ï¼‰
            df['time_index'] = pd.to_timedelta(time_series + ':00').fillna(pd.to_timedelta('00:00:00'))
            
            # æª¢æŸ¥æ˜¯å¦æˆåŠŸ
            if df['time_index'].isna().all():
                raise ValueError("Timedelta è½‰æ›å¤±æ•—")
                
        except:
            # å‚™ç”¨æ–¹æ¡ˆï¼šå˜—è©¦ datetime è½‰æ›
            try:
                datetime_series = pd.to_datetime(time_series, format='%H:%M:%S', errors='coerce')
                if datetime_series.notna().sum() == 0:
                    datetime_series = pd.to_datetime(time_series, errors='coerce')
                
                # è½‰æ›ç‚ºç›¸å°æ™‚é–“
                df['time_index'] = datetime_series - datetime_series.iloc[0]
                
            except Exception as e:
                return None, f"ç„¡æ³•è§£ææ™‚é–“æ ¼å¼ '{time_column}': {e}. æ¨£æœ¬: {time_series.head(3).tolist()}"
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ™‚é–“æ•¸æ“š
        valid_times_mask = df['time_index'].notna()
        if valid_times_mask.sum() == 0:
            return None, f"æ™‚é–“æ¬„ä½ '{time_column}' ä¸­æ²’æœ‰æœ‰æ•ˆçš„æ™‚é–“æ•¸æ“š"
        
        # æ¸…ç†ç„¡æ•ˆæ•¸æ“š
        df = df[valid_times_mask].copy()
        
        # ç¢ºä¿æ™‚é–“å¾0é–‹å§‹
        if len(df) > 0:
            start_time = df['time_index'].iloc[0]
            df['time_index'] = df['time_index'] - start_time
        
        # æ¸…ç†æ•¸æ“šï¼šè™•ç† "-OVER" ç­‰éæ•¸å€¼
        numeric_columns = df.select_dtypes(include=['number']).columns
        for col in numeric_columns:
            if col != 'time_index':
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # æ·»åŠ å‰ç¶´
        df = df.add_prefix('YOKO: ')
        df.rename(columns={'YOKO: time_index': 'time_index'}, inplace=True)
        
        st.success(f"YOKOGAWA è§£ææˆåŠŸï¼æ•¸æ“šè¡Œæ•¸: {len(df)}, æ•¸å€¼æ¬„ä½æ•¸: {len([c for c in df.columns if df[c].dtype in ['float64', 'int64']])}")
        
        return df.set_index('time_index'), "YOKOGAWA Log"
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"è§£æYOKOGAWA Logè©³ç´°éŒ¯èª¤:\n{error_detail}")
        return None, f"è§£æYOKOGAWA Logæ™‚å‡ºéŒ¯: {e}"

# --- ä¸»æ¨¡çµ„ï¼šè§£æå™¨èª¿åº¦ä¸­å¿ƒ (ä¿®æ­£ç‰ˆ) ---
def parse_dispatcher(uploaded_file):
    filename = uploaded_file.name
    file_content = io.BytesIO(uploaded_file.getvalue())
    is_excel = '.xlsx' in filename.lower() or '.xls' in filename.lower()
    
    st.info(f"é–‹å§‹è§£ææ–‡ä»¶: {filename} ({'Excel' if is_excel else 'CSV'})")
    
    try:
        # å°æ–¼Excelæ–‡ä»¶ï¼Œç›´æ¥æª¢æŸ¥æ˜¯å¦ç‚ºYOKOGAWAæ ¼å¼
        if is_excel:
            # æª¢æŸ¥ç¬¬28è¡Œæ˜¯å¦åŒ…å« CH æ¨™è­˜
            try:
                file_content.seek(0)
                df_sniff = pd.read_excel(file_content, header=None, skiprows=27, nrows=1)  # è®€å–ç¬¬28è¡Œ
                
                ch_found = False
                for _, row in df_sniff.iterrows():
                    for cell in row:
                        if isinstance(cell, str) and re.match(r'CH\d{3}', cell.strip()):
                            ch_found = True
                            break
                    if ch_found:
                        break
                
                if ch_found:
                    st.info("æª¢æ¸¬åˆ° YOKOGAWA æ ¼å¼æ¨™è­˜")
                    file_content.seek(0)
                    return parse_yokogawa(file_content, is_excel)
                else:
                    # å³ä½¿æ²’æœ‰æ‰¾åˆ°CHæ¨™è­˜ï¼Œä¹Ÿå˜—è©¦è§£æYOKOGAWAï¼ˆå¯èƒ½æ ¼å¼ç¨æœ‰ä¸åŒï¼‰
                    st.warning("æœªæ‰¾åˆ°æ¨™æº– YOKOGAWA CH æ¨™è­˜ï¼Œä½†ä»å˜—è©¦ YOKOGAWA è§£æ")
                    file_content.seek(0)
                    return parse_yokogawa(file_content, is_excel)
                    
            except Exception as e:
                st.warning(f"Excel æ ¼å¼æª¢æ¸¬å¤±æ•—: {e}ï¼Œå˜—è©¦ç›´æ¥è§£æ")
                file_content.seek(0)
                return parse_yokogawa(file_content, is_excel)
        
        # CSVæ–‡ä»¶çš„PTATæª¢æŸ¥
        else:
            try:
                file_content.seek(0)
                first_lines_text = "".join([file_content.readline().decode('utf-8', errors='ignore') for _ in range(10)])
                file_content.seek(0)
                
                if 'MSR Package Temperature' in first_lines_text:
                    st.info("æª¢æ¸¬åˆ° PTAT æ ¼å¼")
                    return parse_ptat(file_content)
                else:
                    st.warning("æœªæª¢æ¸¬åˆ°å·²çŸ¥æ ¼å¼ï¼Œå˜—è©¦é€šç”¨CSVè§£æ")
                    
            except Exception as e:
                st.error(f"CSV æ ¼å¼æª¢æŸ¥å¤±æ•—: {e}")
        
    except Exception as e:
        st.error(f"æ–‡ä»¶å—…æ¢å¤±æ•—: {e}")
        
    return None, f"æœªçŸ¥çš„Logæª”æ¡ˆæ ¼å¼: {filename}"

# --- åœ–è¡¨ç¹ªè£½å‡½å¼ (ä¿®æ­£ç‰ˆ) ---
def generate_yokogawa_temp_chart(df, x_limits=None):
    """ä¿®æ­£ç‰ˆYOKOGAWAæº«åº¦åœ–è¡¨ï¼Œæ”¯æ´æ™‚é–“ç¯„åœèª¿æ•´"""
    if df is None: 
        return None
    
    # å¥—ç”¨æ™‚é–“ç¯„åœéæ¿¾
    df_chart = df.copy()
    if x_limits:
        x_min_td = pd.to_timedelta(x_limits[0], unit='s')
        x_max_td = pd.to_timedelta(x_limits[1], unit='s')
        df_chart = df_chart[(df_chart.index >= x_min_td) & (df_chart.index <= x_max_td)]
    
    if df_chart.empty:
        return None
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    numeric_cols = df_chart.select_dtypes(include=['number']).columns
    cols_to_plot = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
    
    # é™åˆ¶åœ–è¡¨ä¸­çš„ç·šæ¢æ•¸é‡ï¼Œé¿å…éæ–¼æ··äº‚
    max_channels = 15
    if len(cols_to_plot) > max_channels:
        cols_to_plot = cols_to_plot[:max_channels]
        st.warning(f"é€šé“æ•¸éå¤šï¼Œåƒ…é¡¯ç¤ºå‰ {max_channels} å€‹é€šé“")
    
    for col in cols_to_plot:
        y_data = pd.to_numeric(df_chart[col], errors='coerce')
        # è·³éå…¨ç‚ºNaNçš„æ¬„ä½
        if not y_data.isna().all():
            ax.plot(df_chart.index.total_seconds(), y_data, label=col, linewidth=1)
        
    ax.set_title("YOKOGAWA All Channel Temperature Plot", fontsize=16)
    ax.set_xlabel("Elapsed Time (seconds)", fontsize=12)
    ax.set_ylabel("Temperature (Â°C)", fontsize=12)
    ax.grid(True, linestyle='--', linewidth=0.5)
    ax.legend(title="Channels", bbox_to_anchor=(1.04, 1), loc="upper left", fontsize=8)
    
    # å¦‚æœæœ‰è¨­å®šXè»¸ç¯„åœï¼Œå¥—ç”¨åˆ°åœ–è¡¨
    if x_limits:
        ax.set_xlim(x_limits)
    
    fig.tight_layout()
    return fig

def generate_flexible_chart(df, left_col, right_col, x_limits):
    if df is None or not left_col or left_col not in df.columns: return None
    if right_col and right_col != 'None' and right_col not in df.columns: return None
    df_chart = df.copy()
    if x_limits:
        x_min_td, x_max_td = pd.to_timedelta(x_limits[0], unit='s'), pd.to_timedelta(x_limits[1], unit='s')
        df_chart = df_chart[(df_chart.index >= x_min_td) & (df_chart.index <= x_max_td)]
    if df_chart.empty: return None
    df_chart.loc[:, 'left_val'] = pd.to_numeric(df_chart[left_col], errors='coerce')
    if right_col and right_col != 'None':
        df_chart.loc[:, 'right_val'] = pd.to_numeric(df_chart[right_col], errors='coerce')
    fig, ax1 = plt.subplots(figsize=(12, 6)); plt.title(f'{left_col} {"& " + right_col if right_col and right_col != "None" else ""}', fontsize=16)
    x_axis_seconds = df_chart.index.total_seconds()
    color = 'tab:blue'; ax1.set_xlabel('Elapsed Time (seconds)', fontsize=12); ax1.set_ylabel(left_col, color=color, fontsize=12)
    ax1.plot(x_axis_seconds, df_chart['left_val'], color=color); ax1.tick_params(axis='y', labelcolor=color); ax1.grid(True, linestyle='--', linewidth=0.5)
    if right_col and right_col != 'None':
        ax2 = ax1.twinx(); color = 'tab:red'
        ax2.set_ylabel(right_col, color=color, fontsize=12); ax2.plot(x_axis_seconds, df_chart['right_val'], color=color)
        ax2.tick_params(axis='y', labelcolor=color)
    if x_limits: ax1.set_xlim(x_limits)
    fig.tight_layout()
    return fig

# --- Streamlit ç¶²é æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(layout="wide")
st.title("é€šç”¨æ•¸æ“šåˆ†æå¹³å° - YOKOGAWA æ™‚é–“ç¯„åœèª¿æ•´ç‰ˆ")
st.sidebar.header("æ§åˆ¶é¢æ¿")
uploaded_files = st.sidebar.file_uploader("ä¸Šå‚³Log File (å¯å¤šé¸)", type=['csv', 'xlsx'], accept_multiple_files=True)
st.sidebar.info("æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ç‚ºYOKOGAWAåœ–è¡¨åŠ å…¥äº†æ™‚é–“ç¯„åœèª¿æ•´åŠŸèƒ½ã€‚")

if uploaded_files:
    # --- é—œéµä¿®æ­£ï¼šåªåœ¨éœ€è¦æ™‚æ‰é€²è¡Œæª”æ¡ˆé¡å‹é åˆ¤ ---
    if len(uploaded_files) == 1:
        # å‚³éå®Œæ•´çš„æª”æ¡ˆç‰©ä»¶é€²è¡Œé åˆ¤
        df_check, log_type_check = parse_dispatcher(uploaded_files[0])
        is_single_yokogawa = (log_type_check == "YOKOGAWA Log")
    else:
        is_single_yokogawa = False

    # --- YOKOGAWA å°ˆå±¬é¡¯ç¤ºæ¨¡å¼ (æ–°å¢æ™‚é–“ç¯„åœèª¿æ•´) ---
    if is_single_yokogawa:
        st.sidebar.success(f"æª”æ¡ˆ '{uploaded_files[0].name}'\n(è¾¨è­˜ç‚º: YOKOGAWA Log)")
        
        # ğŸ”¥ æ–°å¢ï¼šYOKOGAWA æ™‚é–“ç¯„åœèª¿æ•´æ§åˆ¶é …
        st.sidebar.header("YOKOGAWA åœ–è¡¨è¨­å®š")
        if df_check is not None and len(df_check) > 0:
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            x_min_val = df_check.index.min().total_seconds()
            x_max_val = df_check.index.max().total_seconds()
            
            if x_min_val < x_max_val:
                x_min, x_max = st.sidebar.slider(
                    "é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", 
                    float(x_min_val), 
                    float(x_max_val), 
                    (float(x_min_val), float(x_max_val)),
                    key="yokogawa_time_range"
                )
                x_limits = (x_min, x_max)
            else:
                st.sidebar.write("æ•¸æ“šæ™‚é–“ç¯„åœä¸è¶³ã€‚")
                x_limits = None
        else:
            x_limits = None
        
        st.header("YOKOGAWA å…¨é€šé“æº«åº¦æ›²ç·šåœ–")
        
        # ç›´æ¥ä½¿ç”¨é åˆ¤æ™‚å·²è§£æçš„ DataFrameï¼Œä¸¦å¥—ç”¨æ™‚é–“ç¯„åœ
        if df_check is not None:
            st.write(f"æ•¸æ“šæ¦‚æ³ï¼š{len(df_check)} ç­†è¨˜éŒ„ï¼Œ{len(df_check.columns)} å€‹æ¬„ä½")
            
            # ğŸ”¥ ä¿®æ­£ï¼šå°‡æ™‚é–“ç¯„åœåƒæ•¸å‚³éçµ¦åœ–è¡¨å‡½å¼
            fig = generate_yokogawa_temp_chart(df_check, x_limits)
            if fig: 
                st.pyplot(fig)
            else: 
                st.warning("ç„¡æ³•ç”¢ç”ŸYOKOGAWAæº«åº¦åœ–è¡¨ã€‚")
        else:
            st.error("DataFrame ç‚ºç©ºï¼Œç„¡æ³•ç¹ªè£½åœ–è¡¨")

    # --- é€šç”¨äº’å‹•å¼åˆ†ææ¨¡å¼ (é©ç”¨æ–¼PTATæˆ–å¤šæª”æ¡ˆ) ---
    else:
        all_dfs = []; log_types_detected = []
        with st.spinner('æ­£åœ¨è§£ææ‰€æœ‰Logæª”æ¡ˆ...'):
            for file in uploaded_files:
                df, log_type = parse_dispatcher(file)
                if df is not None:
                    all_dfs.append(df); log_types_detected.append(f"{file.name} (è¾¨è­˜ç‚º: {log_type})")
                else:
                    st.error(f"æª”æ¡ˆ '{file.name}' è§£æå¤±æ•—: {log_type}")
        
        if all_dfs:
            st.sidebar.success("æª”æ¡ˆè§£æå®Œæˆï¼")
            for name in log_types_detected: st.sidebar.markdown(f"- `{name}`")
            master_df = pd.concat(all_dfs); 
            master_df_resampled = master_df.select_dtypes(include=['number']).resample('1S').mean(numeric_only=True).interpolate(method='linear')
            numeric_columns = master_df_resampled.columns.tolist()

            if numeric_columns:
                st.sidebar.header("åœ–è¡¨è¨­å®š")
                default_left_list = [c for c in numeric_columns if 'Temp' in c or 'T_' in c or 'CPU' in c]
                default_left = default_left_list[0] if default_left_list else numeric_columns[0]
                left_y_axis = st.sidebar.selectbox("é¸æ“‡å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=numeric_columns.index(default_left) if default_left in numeric_columns else 0)
                right_y_axis_options = ['None'] + numeric_columns
                default_right_index = 0
                if len(numeric_columns) > 1:
                    default_right_list = [c for c in numeric_columns if 'Power' in c or 'Watt' in c or 'P_' in c]
                    default_right = default_right_list[0] if default_right_list else 'None'
                    try: default_right_index = right_y_axis_options.index(default_right)
                    except ValueError: default_right_index = 1
                right_y_axis = st.sidebar.selectbox("é¸æ“‡å³å´Yè»¸è®Šæ•¸ (å¯ä¸é¸)", options=right_y_axis_options, index=default_right_index)
                st.sidebar.header("Xè»¸ç¯„åœè¨­å®š (ç§’)")
                x_min_val = master_df_resampled.index.min().total_seconds(); x_max_val = master_df_resampled.index.max().total_seconds()
                if x_min_val < x_max_val:
                    x_min, x_max = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ", x_min_val, x_max_val, (x_min_val, x_max_val))
                else:
                    st.sidebar.write("æ•¸æ“šæ™‚é–“ç¯„åœä¸è¶³ã€‚"); x_min, x_max = x_min_val, x_max_val
                st.header("å‹•æ…‹æ¯”è¼ƒåœ–è¡¨")
                fig = generate_flexible_chart(master_df_resampled, left_y_axis, right_y_axis, (x_min, x_max))
                if fig: st.pyplot(fig)
            else:
                st.warning("æ‰€æœ‰æª”æ¡ˆè§£æå¾Œï¼Œç„¡å¯ç”¨çš„æ•¸å€¼å‹æ•¸æ“šé€²è¡Œç¹ªåœ–ã€‚")
else:
    st.sidebar.info("è«‹ä¸Šå‚³æ‚¨çš„ Log File(s) é–‹å§‹åˆ†æã€‚")
